# 1. 概述

关键类位置：

| 名称                 | 路径                                                 |
| -------------------- | ---------------------------------------------------- |
| audioserver.rc       | frameworks/av/media/audioserver/audioserver.rc       |
| main_audioserver.cpp | frameworks/av/media/audioserver/main_audioserver.cpp |
| processState.cpp     | frameworks/native/libs/binder                        |
| IServiceManager.cpp  | frameworks/native/libs/binder                        |
| AudioTrack.cpp       | frameworks/av/media/libaudioclient                   |
|                      |                                                      |
|                      |                                                      |
|                      |                                                      |
|                      |                                                      |

关键so/exe/jar源文件位置：

| 名称                     | 路径                                                 |
| ------------------------ | ---------------------------------------------------- |
| audioserver.exe          | frameworks/av/media/audioserver/                     |
| libaudioservice.so       |                                                      |
| libaudioflinger.so       | frameworks/av/services/audioflinger/                 |
| libaudiopolicyservice.so | frameworks/av/services/audiopolicy/services/service/ |
| libaudioclient.so        | frameworks/av/media/libaudioclient/                  |

audioserver依赖的共享库：

![image-20210921102707057](.\images\image-20210921102707057.png)

音频框架图：

![](.\images\音频框架图.png)

# 2 audioserver进程启动

启动配置文件：audioserver.rc：

```
frameworks/av/media/audioserver/audioserver.rc

service audioserver /system/bin/audioserver
    class core
    user audioserver
    # media gid needed for /dev/fm (radio) and for /data/misc/media (tee)
    group audio camera drmrpc media mediadrm net_bt net_bt_admin net_bw_acct wakelock
    capabilities BLOCK_SUSPEND
    ioprio rt 4
    task_profiles ProcessCapacityHigh HighPerformance
    onrestart restart vendor.audio-hal
    onrestart restart vendor.audio-hal-4-0-msd
    # Keep the original service names for backward compatibility
    onrestart restart vendor.audio-hal-2-0
    onrestart restart audio-hal-2-0
```

启动入口位于main_audioserver.cpp

```C++
frameworks/av/media/audioserver/main_audioserver.cpp

int main(int argc __unused, char **argv)
{
    // TODO: update with refined parameters
    limitProcessMemory(
        "audio.maxmem", /* "ro.audio.maxmem", property that defines limit */
        (size_t)512 * (1 << 20), /* SIZE_MAX, upper limit in bytes */
        20 /* upper limit as percentage of physical RAM */);

    signal(SIGPIPE, SIG_IGN);

#if 1
    // FIXME See bug 165702394 and bug 168511485
    const bool doLog = false;
#else
    bool doLog = (bool) property_get_bool("ro.test_harness", 0);
#endif

    pid_t childPid;
    if (doLog && (childPid = fork()) != 0) {
        // 因为doLog是false，这部分代码省略
        ......        
    } else {
        // all other services
        if (doLog) {
        // 因为doLog是false，这部分代码省略
        ......    
        }
        
        // 核心代码start
        android::hardware::configureRpcThreadpool(4, false /*callerWillJoin*/);
        sp<ProcessState> proc(ProcessState::self());
        sp<IServiceManager> sm = defaultServiceManager();
        ALOGI("ServiceManager: %p", sm.get());
        AudioFlinger::instantiate();
        AudioPolicyService::instantiate();

        // AAudioService should only be used in OC-MR1 and later.
        // And only enable the AAudioService if the system MMAP policy explicitly allows it.
        // This prevents a client from misusing AAudioService when it is not supported.
        aaudio_policy_t mmapPolicy = property_get_int32(AAUDIO_PROP_MMAP_POLICY,
                                                        AAUDIO_POLICY_NEVER);
        if (mmapPolicy == AAUDIO_POLICY_AUTO || mmapPolicy == AAUDIO_POLICY_ALWAYS) {
            AAudioService::instantiate();
        }

        ProcessState::self()->startThreadPool();
        IPCThreadState::self()->joinThreadPool();
        // 核心代码end
    }
}
```

抽取核心代码：

```C++
frameworks/av/media/audioserver/main_audioserver.cpp

int main(int argc __unused, char **argv)
{   
    // 一、获得一个ProcessState的实例
    sp<ProcessState> proc(ProcessState::self());
    // 二、audioServer进程作为ServiceManager的客户端，需要向ServiceManager注册服务
    // 调用defaultServiceManager()得到一个IserviceManager
    sp<IServiceManager> sm = defaultServiceManager();
    // 三、初始化音频系统的AudioFlinger服务
    AudioFlinger::instantiate();
    // 四、初始化音频系统的AudioPolicyService服务
    AudioPolicyService::instantiate();

    // 五、按需初始化音频系统的AAudioService服务
    aaudio_policy_t mmapPolicy = property_get_int32(AAUDIO_PROP_MMAP_POLICY,
    AAUDIO_POLICY_NEVER);
    if (mmapPolicy == AAUDIO_POLICY_AUTO || mmapPolicy == AAUDIO_POLICY_ALWAYS) {
    AAudioService::instantiate();
    }

    // 六、创建一个线程池
    ProcessState::self()->startThreadPool();
    // 将自己加入该线程池
    IPCThreadState::self()->joinThreadPool();
    }
}
```

上面的核心步骤会分别展开说明

## 2.1 ProcessState::self

主要针对这行代码展开说明：

```C++
// main_audioserver.cpp
	// 一、获得一个ProcessState的实例
    sp<ProcessState> proc(ProcessState::self());
```

```C++
// ProcessState.cpp

sp<ProcessState> ProcessState::self()
{
    return init(kDefaultDriver, false);
}

// 通过std::once_flag和std::call_once实现单例，即sp<ProcessState>::make(driver)只调用一次
// 相应的，gProcess也只初始化一次
sp<ProcessState> ProcessState::init(const char *driver, bool requireDefault)
{
    [[clang::no_destroy]] static sp<ProcessState> gProcess;
    [[clang::no_destroy]] static std::mutex gProcessMutex;

    if (driver == nullptr) {
        std::lock_guard<std::mutex> l(gProcessMutex);
        return gProcess;
    }

    [[clang::no_destroy]] static std::once_flag gProcessOnce;
    std::call_once(gProcessOnce, [&](){
        if (access(driver, R_OK) == -1) {
            ALOGE("Binder driver %s is unavailable. Using /dev/binder instead.", driver);
            driver = "/dev/binder";
        }

        std::lock_guard<std::mutex> l(gProcessMutex);
        gProcess = sp<ProcessState>::make(driver);
    });

    return gProcess;
}
```

sp<ProcessState>智能指针的make函数，实际上是执行了ProcessState的构造函数，然后返回智能指针

```C++
// StrongPointer.h
template <typename T>
template <typename... Args>
sp<T> sp<T>::make(Args&&... args) {
    T* t = new T(std::forward<Args>(args)...);
    sp<T> result;
    result.m_ptr = t;
    t->incStrong(t);  // bypass check_not_on_stack for heap allocation
    return result;
}
```

查看ProcessState的构造函数

```C++
// ProcessState.cpp

ProcessState::ProcessState(const char *driver)
    : mDriverName(String8(driver))
        // 打开/dev/binder这个设备，这是android在内核中专门用于完成进程间通信而设置的一个虚拟设备。
    , mDriverFD(open_driver(driver))
    , mVMStart(MAP_FAILED)
    , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER)
    , mThreadCountDecrement(PTHREAD_COND_INITIALIZER)
    , mExecutingThreadsCount(0)
    , mWaitingForThreads(0)
    , mMaxThreads(DEFAULT_MAX_BINDER_THREADS)
    , mStarvationStartTimeMs(0)
    , mThreadPoolStarted(false)
    , mThreadPoolSeq(1)
    , mCallRestriction(CallRestriction::NONE)
{

    if (mDriverFD >= 0) {
        // mmap the binder, providing a chunk of virtual address space to receive transactions.
        mVMStart = mmap(nullptr, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0);
        if (mVMStart == MAP_FAILED) {
            // *sigh*
            ALOGE("Using %s failed: unable to mmap transaction memory.\n", mDriverName.c_str());
            close(mDriverFD);
            mDriverFD = -1;
            mDriverName.clear();
        }
    }
}
```

总结，ProcessState::self做了三件事：

- 打开/dev/binder设备，这就相当于与内核的Binder驱动有了交互的通道。
- 对返回的fd使用mmap，这样Binder驱动就会分配一块内存来接收数据。
- 由于ProcessState的惟一性，因此一个进程只打开设备一次。

## 2.2 defaultServiceManager

主要针对这行代码展开说明：

```C++
// 二、audioServer进程作为ServiceManager的客户端，需要向ServiceManager注册服务
    // 调用defaultServiceManager()得到一个IserviceManager
    sp<IServiceManager> sm = defaultServiceManager();
```

defaultServiceManager()函数位于IServiceManager.cpp：

```C++
// IServiceManager.cpp

using AidlServiceManager = android::os::IServiceManager;

[[clang::no_destroy]] static std::once_flag gSmOnce;
[[clang::no_destroy]] static sp<IServiceManager> gDefaultServiceManager;

sp<IServiceManager> defaultServiceManager()
{
    // 可以看到也是个单例
    std::call_once(gSmOnce, []() {
        sp<AidlServiceManager> sm = nullptr;
        while (sm == nullptr) {
            sm = interface_cast<AidlServiceManager>(ProcessState::self()->getContextObject(nullptr));
            if (sm == nullptr) {
                ALOGE("Waiting 1s on context object on %s.", ProcessState::self()->getDriverName().c_str());
                sleep(1);
            }
        }

        gDefaultServiceManager = sp<ServiceManagerShim>::make(sm);
    });

    return gDefaultServiceManager;
}
```

//  TODO

https://www.kancloud.cn/alex_wsc/android_depp/412925

## AudioFlinger::instantiate

## AudioPolicyService::instantiate

## AAudioServcei::instantiate

## start&joinThreadPool

# 3. MediaPlayer到AudioTrack

这一节重点梳理下应用层调用MediaPlayer后，是如何一步步创建AudioTrack的。

## 3.1 应用层代码

简单的使用MediaPlayer的播放流程，播放assets下的音频文件。

```java
package com.colin.mediaplayerdemo;

import ...

public class MainActivity extends AppCompatActivity implements View.OnClickListener {
    private Button mPlay;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        initView();
    }

    private void initView() {
        mPlay = findViewById(R.id.play);
        mPlay.setOnClickListener(this);
    }

    @Override
    public void onClick(View v) {
        switch (v.getId()) {
            case R.id.play:
                try {
                    MediaPlayer mp = new MediaPlayer();
                    mp.setOnPreparedListener(mediaPlayer -> mediaPlayer.start());
                    AssetManager assetMg = this.getApplicationContext().getAssets();
                    AssetFileDescriptor fileDescriptor = null;
                    fileDescriptor = assetMg.openFd("music.mp3");
                    mp.setDataSource(fileDescriptor.getFileDescriptor(), fileDescriptor.getStartOffset(), fileDescriptor.getLength());
                    mp.prepare();
                } catch (IOException e) {
                    e.printStackTrace();
                }
                break;
            default:
                break;
        }
    }
}
```

## 3.2 MediaPlayer的调用流程

简单看下MediaPlayer的调用流程

![image-20210921132855725](.\images\image-20210921132855725.png)

实际上，不仅仅是MediaPlayer，其他很多地方也是类似的。上面通过jni透传到native的就不关注了，主要关注下binder的部分。

## 3.3 setDataSource

setDataSource为例，看下mediaplayer.cpp是怎么调用服务侧的：

> mediaplayer

```c++
status_t MediaPlayer::setDataSource(int fd, int64_t offset, int64_t length)
{
    ALOGV("setDataSource(%d, %" PRId64 ", %" PRId64 ")", fd, offset, length);
    status_t err = UNKNOWN_ERROR;
    // 获取IMediaPlayerService，实际上是BpMediaPlayerService
    const sp<IMediaPlayerService> service(getMediaPlayerService());
    if (service != 0) {
        // 调用BpMediaPlayerService的函数，返回获取IMediaPlayer,实际上拿到的是BpMediaPlayer
        sp<IMediaPlayer> player(service->create(this, mAudioSessionId, mOpPackageName));
        if ((NO_ERROR != doSetRetransmitEndpoint(player)) ||
            // 调用IMediaPlayer（BpMediaPlayer）的同名方法
            (NO_ERROR != player->setDataSource(fd, offset, length))) {
            player.clear();
        }
        err = attachNewPlayer(player);
    }
    return err;
}
```

BpMediaPlayer最终会调用到BnMediaPlayer子类，也就是MediaPlayerService::Client的同名方法：

> 有兴趣可以看下MediaPlayer这块的binder接口定义，包括IMediaPlayerClient，IMediaPlayer，IMediaPlayerService。这里就不展开了。

> MediaPlayerService::Client

```c++
status_t MediaPlayerService::Client::setDataSource(int fd, int64_t offset, int64_t length)
{
	// 获取文件类型
    player_type playerType = MediaPlayerFactory::getPlayerType(this,
                                                               fd,
                                                               offset,
                                                               length);
    // 预处理，拿到MediaPlayerBase对象
    sp<MediaPlayerBase> p = setDataSource_pre(playerType);
    if (p == NULL) {
        return NO_INIT;
    }

    // 执行MediaPlayerBase的setDataSource
    return mStatus = setDataSource_post(p, p->setDataSource(fd, offset, length));
}
```

### 3.3.1 setDataSource_pre

不同的文件对应不同的播放器类，播放器类的公共父类为MediaPlayerBase，所以setDataSource_pre类似于一个生产MediaPlayerBase的工厂，传参是具体的player类型，下面看下这个工厂是如何实现的:

```C++
sp<MediaPlayerBase> MediaPlayerService::Client::setDataSource_pre(
        player_type playerType)
{

    sp<MediaPlayerBase> p = createPlayer(playerType);
    if (p == NULL) {
        return p;
    }

    if (!p->hardwareOutput()) {
        mAudioOutput = new AudioOutput(mAudioSessionId, IPCThreadState::self()->getCallingUid(),
                mPid, mAudioAttributes, mAudioDeviceUpdatedListener, mOpPackageName);
        static_cast<MediaPlayerInterface*>(p.get())->setAudioSink(mAudioOutput);
    }

    return p;
}
```

看下cratePlayer:

```C++
sp<MediaPlayerBase> MediaPlayerService::Client::createPlayer(player_type playerType)
{
    sp<MediaPlayerBase> p = getPlayer();
    if ((p != NULL) && (p->playerType() != playerType)) {
        ALOGV("delete player");
        p.clear();
    }
    if (p == NULL) {
        // getPlayer()返回mPlayer成员，此时必然为null，走到本分支
        p = MediaPlayerFactory::createPlayer(playerType, mListener, mPid);
    }

    if (p != NULL) {
        p->setUID(mUid);
    }

    return p;
}
```

ok，看下MediaPlayerFactory这个工厂类：

> MediaPlayerFactory

```C++
sp<MediaPlayerBase> MediaPlayerFactory::createPlayer(
        player_type playerType,
        const sp<MediaPlayerBase::Listener> &listener,
        pid_t pid) {
    sp<MediaPlayerBase> p;
    IFactory* factory;

    // 核心在于sFactoryMap是什么时候初始化的
    factory = sFactoryMap.valueFor(playerType);
    CHECK(NULL != factory);
    p = factory->createPlayer(pid);

    return p;
}
```

看下sFactoryMap的写入时机，找到一个函数：

```C++
status_t MediaPlayerFactory::registerFactory_l(IFactory* factory,
                                               player_type type) {

    if (sFactoryMap.add(type, factory) < 0) {
        ALOGE("Failed to register MediaPlayerFactory of type %d, failed to add"
              " to map.", type);
        return UNKNOWN_ERROR;
    }

    return OK;
}
```

搜索registerFactory_l的调用，找到两个核心的位置：

> 位置1：MediaPlayerFactory::registerFactory

```C++
status_t MediaPlayerFactory::registerFactory(IFactory* factory,
                                             player_type type) {
    Mutex::Autolock lock_(&sLock);
    return registerFactory_l(factory, type);
}
```

> 位置2：MediaPlayerFactory::registerBuiltinFacotories

```C++
void MediaPlayerFactory::registerBuiltinFactories() {
    Mutex::Autolock lock_(&sLock);

    if (sInitComplete)
        return;

    IFactory* factory = new NuPlayerFactory();
    if (registerFactory_l(factory, NU_PLAYER) != OK)
        delete factory;
    factory = new TestPlayerFactory();
    if (registerFactory_l(factory, TEST_PLAYER) != OK)
        delete factory;

    sInitComplete = true;
}
```

到这里可以大概知道至少有两个Player：

> NuPlayerFactory和TestPlayerFactory

后者明显是测试用的，实际上，手机厂商可以拓展registerBuiltinFactories()，从而实现自己的Player

> 那么问题来了，sFactoryMap中有那么多的Factory，MediaPlayerFactory是如何知道返回哪个Factory的呢

直接看下IFactory接口：

```C++
    class IFactory {
      public:
        virtual ~IFactory() { }

        virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                                   const char* /*url*/,
                                   float /*curScore*/) { return 0.0; }

        virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                                   int /*fd*/,
                                   int64_t /*offset*/,
                                   int64_t /*length*/,
                                   float /*curScore*/) { return 0.0; }

        virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                                   const sp<IStreamSource> &/*source*/,
                                   float /*curScore*/) { return 0.0; }

        virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                                   const sp<DataSource> &/*source*/,
                                   float /*curScore*/) { return 0.0; }

        virtual sp<MediaPlayerBase> createPlayer(pid_t pid) = 0;
    };
```

可以看到IFactory接口中定义了两个函数，一个是createPlayer()，也就是用来创建我们的MediaPlayerBase播放器的。另一个叫scoreFactory()，顾名思义，这个函数可以计算一个分数。

> 实际上，MediaPlayerFactory会根据媒体文件的类型，调用sFactoryMap中，每个Factory的scoreFactory()函数，返回得分最高的Factory。

这里返回的是NuPlayerFactory：

```C++
class NuPlayerFactory : public MediaPlayerFactory::IFactory {
  public:
    virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                               const char* url,
                               float curScore) {
        static const float kOurScore = 0.8;

        if (kOurScore <= curScore)
            return 0.0;

        if (!strncasecmp("http://", url, 7)
                || !strncasecmp("https://", url, 8)
                || !strncasecmp("file://", url, 7)) {
            size_t len = strlen(url);
            if (len >= 5 && !strcasecmp(".m3u8", &url[len - 5])) {
                return kOurScore;
            }

            if (strstr(url,"m3u8")) {
                return kOurScore;
            }

            if ((len >= 4 && !strcasecmp(".sdp", &url[len - 4])) || strstr(url, ".sdp?")) {
                return kOurScore;
            }
        }

        if (!strncasecmp("rtsp://", url, 7)) {
            return kOurScore;
        }

        return 0.0;
    }

    virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                               const sp<IStreamSource>& /*source*/,
                               float /*curScore*/) {
        return 1.0;
    }

    virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                               const sp<DataSource>& /*source*/,
                               float /*curScore*/) {
        // Only NuPlayer supports setting a DataSource source directly.
        return 1.0;
    }

    virtual sp<MediaPlayerBase> createPlayer(pid_t pid) {
        ALOGV(" create NuPlayer");
        return new NuPlayerDriver(pid);
    }
};
```

NuPlayerFactory创建的MediaPlayerBase是：NuPlayerDriver

### 3.3.2 setDataSource_post

继续看下setDataSource_post：

```C++
status_t MediaPlayerService::Client::setDataSource(int fd, int64_t offset, int64_t length)
{
	// 获取文件类型
    player_type playerType = MediaPlayerFactory::getPlayerType(this,
                                                               fd,
                                                               offset,
                                                               length);
    // 预处理，拿到MediaPlayerBase对象
    sp<MediaPlayerBase> p = setDataSource_pre(playerType);
    if (p == NULL) {
        return NO_INIT;
    }

    // 执行MediaPlayerBase的setDataSource
    return mStatus = setDataSource_post(p, p->setDataSource(fd, offset, length));
}
```

一步步来，首先是NuPlayerDriver::setDataSource()

> NuPlayerDriver::setDataSource

```C++
status_t NuPlayerDriver::setDataSource(int fd, int64_t offset, int64_t length) {
    ALOGV("setDataSource(%p) file(%d)", this, fd);
    Mutex::Autolock autoLock(mLock);

    if (mState != STATE_IDLE) {
        return INVALID_OPERATION;
    }

    mState = STATE_SET_DATASOURCE_PENDING;

    mPlayer->setDataSourceAsync(fd, offset, length);

    while (mState == STATE_SET_DATASOURCE_PENDING) {
        mCondition.wait(mLock);
    }

    return mAsyncResult;
}
```

OK，看来需要先搞清楚NuPlayerDriver::mPlayer是啥，啥时候初始化的：

```C++
// mPlayer是啥？
const sp<NuPlayer> mPlayer;

// mPlayer啥时候初始化的？
NuPlayerDriver::NuPlayerDriver(pid_t pid)
    : mState(STATE_IDLE),
      ...
      mPlayer(new NuPlayer(pid, mMediaClock)),
	  ...
```

好吧，猜测这个NuPlayerDriver也只是套壳，实际上执行功能的是NuPlayer

继续看NuPlayer::setDataSourceAsync()，顾名思义，这是个异步操作：

```c++
void NuPlayer::setDataSourceAsync(int fd, int64_t offset, int64_t length) {
    sp<AMessage> msg = new AMessage(kWhatSetDataSource, this);

    sp<AMessage> notify = new AMessage(kWhatSourceNotify, this);

    sp<GenericSource> source =
            new GenericSource(notify, mUIDValid, mUID, mMediaClock);

    status_t err = source->setDataSource(fd, offset, length);

    if (err != OK) {
        ALOGE("Failed to set data source!");
        source = NULL;
    }

    msg->setObject("source", source);
    msg->post();
    mDataSourceType = DATA_SOURCE_TYPE_GENERIC_FD;
}
```

emmm，看到了AMessage，应该是跟java侧的Handler类似的功能吧，姑且先理解为，NuPlayer把setDataSource的任务post到子线程去做了。具体关于AMessage，后面有时间再研究。

注意到有两个AMessage，首先看第一个kWhatSetDataSource，创建了一个GenericSource对象，作为消息内容发出：

```C++
void NuPlayer::onMessageReceived(const sp<AMessage> &msg) {
    switch (msg->what()) {
        case kWhatSetDataSource:
        {
            ALOGV("kWhatSetDataSource");

            CHECK(mSource == NULL);

            status_t err = OK;
            sp<RefBase> obj;
            CHECK(msg->findObject("source", &obj));
            if (obj != NULL) {
                Mutex::Autolock autoLock(mSourceLock);
                mSource = static_cast<Source *>(obj.get());
            } else {
                err = UNKNOWN_ERROR;
            }

            CHECK(mDriver != NULL);
            // 升级为强指针，然后通知NuPlayerDriver
            sp<NuPlayerDriver> driver = mDriver.promote();
            if (driver != NULL) {
                driver->notifySetDataSourceCompleted(err);
            }
            break;
        }
        ...
```

接收到kWhatSetDataSource的消息接收到后，直接通知下NuPlayerDriver，这块没有太多耗时的操作，异步与否其实无所谓。

重点看下另一个AMessage：kWhatSourceNotify

```C++
    sp<AMessage> notify = new AMessage(kWhatSourceNotify, this);

    sp<GenericSource> source =
            new GenericSource(notify, mUIDValid, mUID, mMediaClock);

    status_t err = source->setDataSource(fd, offset, length);
```

看下这个类：GenericSource：

> GenericSource

```C++
struct NuPlayer::GenericSource : public NuPlayer::Source,
                                 public MediaBufferObserver {
                                 }
```

GenericSource是NuPlayer::Source的一个子类，主要用于本地多媒体文件的读取解析，其他还有：

> NuPlayer::Source的子类有：GenericSource、HTTPLiveSource、RTSPSource、StreamingSource

先看GenericSource的构造函数：

```C++
NuPlayer::GenericSource::GenericSource(
        const sp<AMessage> &notify,
        bool uidValid,
        uid_t uid,
        const sp<MediaClock> &mediaClock)
    : Source(notify),
    	...  
	{
    ALOGV("GenericSource");
    CHECK(mediaClock != NULL);

    mBufferingSettings.mInitialMarkMs = kInitialMarkMs;
    mBufferingSettings.mResumePlaybackMarkMs = kResumePlaybackMarkMs;
    resetDataSource();
}

explicit Source(const sp<AMessage> &notify)
    : mNotify(notify) {
}

sp<AMessage> mNotify;
```

注意到notify被传过来了。

继续看GenericSource::setDataSource

```C++
status_t NuPlayer::GenericSource::setDataSource(
        int fd, int64_t offset, int64_t length) {
    Mutex::Autolock _l(mLock);
    ALOGV("setDataSource %d/%lld/%lld (%s)", fd, (long long)offset, (long long)length, nameForFd(fd).c_str());

    resetDataSource();

    mFd.reset(dup(fd));
    mOffset = offset;
    mLength = length;

    // delay data source creation to prepareAsync() to avoid blocking
    // the calling thread in setDataSource for any significant time.
    return OK;
}
```

做了写状态设置，跟AudioTrack没有什么关系，就不继续展开看了。

## 3.4 prepare

继续看prepare()函数：

> mediaplayer::prepare()

```C++
status_t MediaPlayer::prepare()
{
    ALOGV("prepare");
    Mutex::Autolock _l(mLock);
    mLockThreadId = getThreadId();
    if (mPrepareSync) {
        mLockThreadId = 0;
        return -EALREADY;
    }
    mPrepareSync = true;
    status_t ret = prepareAsync_l();
    if (ret != NO_ERROR) {
        mLockThreadId = 0;
        return ret;
    }

    if (mPrepareSync) {
        mSignal.wait(mLock);  // wait for prepare done
        mPrepareSync = false;
    }
    ALOGV("prepare complete - status=%d", mPrepareStatus);
    mLockThreadId = 0;
    return mPrepareStatus;
}
```

```c++
status_t MediaPlayer::prepareAsync_l()
{
    if ( (mPlayer != 0) && ( mCurrentState & (MEDIA_PLAYER_INITIALIZED | MEDIA_PLAYER_STOPPED) ) ) {
        if (mAudioAttributesParcel != NULL) {
            mPlayer->setParameter(KEY_PARAMETER_AUDIO_ATTRIBUTES, *mAudioAttributesParcel);
        } else {
            mPlayer->setAudioStreamType(mStreamType);
        }
        mCurrentState = MEDIA_PLAYER_PREPARING;
        return mPlayer->prepareAsync();
    }
    ALOGE("prepareAsync called in state %d, mPlayer(%p)", mCurrentState, mPlayer.get());
    return INVALID_OPERATION;
}
```

分析setDataSource的时候已知，MediaPlayer的mPlayer是MediaPlayerService::Client的代理：

> MediaPlayerService::Client

```C++
status_t MediaPlayerService::Client::prepareAsync()
{
    ALOGV("[%d] prepareAsync", mConnId);
    sp<MediaPlayerBase> p = getPlayer();
    if (p == 0) return UNKNOWN_ERROR;
    status_t ret = p->prepareAsync();
#if CALLBACK_ANTAGONIZER
    ALOGD("start Antagonizer");
    if (ret == NO_ERROR) mAntagonizer->start();
#endif
    return ret;
}
```

> NuPlayerDriver::prepareAsync

```C++
status_t NuPlayerDriver::prepareAsync() {
    ALOGV("prepareAsync(%p)", this);
    Mutex::Autolock autoLock(mLock);

    switch (mState) {
        case STATE_UNPREPARED:
            mState = STATE_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->prepareAsync();
            return OK;
        case STATE_STOPPED:
            // this is really just paused. handle as seek to start
            mAtEOS = false;
            mState = STATE_STOPPED_AND_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->seekToAsync(0, MediaPlayerSeekMode::SEEK_PREVIOUS_SYNC /* mode */,
                    true /* needNotify */);
            return OK;
        default:
            return INVALID_OPERATION;
    };
}
```

### 3.4.1 mState值是多少？

首先看下NuPlayerDriver::mState，在执行setDataSource后，NuPlayer会通知NuPlayerDriver执行完成：

```C++
void NuPlayer::onMessageReceived(const sp<AMessage> &msg) {
    switch (msg->what()) {
        case kWhatSetDataSource:
        {
            ALOGV("kWhatSetDataSource");

            CHECK(mSource == NULL);

            status_t err = OK;
            sp<RefBase> obj;
            CHECK(msg->findObject("source", &obj));
            if (obj != NULL) {
                Mutex::Autolock autoLock(mSourceLock);
                mSource = static_cast<Source *>(obj.get());
            } else {
                err = UNKNOWN_ERROR;
            }

            CHECK(mDriver != NULL);
            // 升级为强指针，然后通知NuPlayerDriver
            sp<NuPlayerDriver> driver = mDriver.promote();
            if (driver != NULL) {
                driver->notifySetDataSourceCompleted(err);
            }
            break;
        }
        ...
```

```C++
void NuPlayerDriver::notifySetDataSourceCompleted(status_t err) {
    Mutex::Autolock autoLock(mLock);

    CHECK_EQ(mState, STATE_SET_DATASOURCE_PENDING);

    mAsyncResult = err;
    mState = (err == OK) ? STATE_UNPREPARED : STATE_IDLE;
    mCondition.broadcast();
}
```

可以看到，此时mState为STATE_UNPREPARED

### 3.4.2 NuPlayer::prepareAsync

回到NuPlayerDriver::prepareAsync：

```C++
status_t NuPlayerDriver::prepareAsync() {
    ALOGV("prepareAsync(%p)", this);
    Mutex::Autolock autoLock(mLock);

    switch (mState) {
        case STATE_UNPREPARED:
            mState = STATE_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->prepareAsync();
            return OK;
        case STATE_STOPPED:
            // this is really just paused. handle as seek to start
            mAtEOS = false;
            mState = STATE_STOPPED_AND_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->seekToAsync(0, MediaPlayerSeekMode::SEEK_PREVIOUS_SYNC /* mode */,
                    true /* needNotify */);
            return OK;
        default:
            return INVALID_OPERATION;
    };
}
```

上面已经分析过了，mState为STATE_UNPREPARED，所以执行NuPlayer::prepareAsync()

```C++
void NuPlayer::prepareAsync() {
    ALOGV("prepareAsync");

    (new AMessage(kWhatPrepare, this))->post();
}
```

```C++
        case kWhatPrepare:
        {
            ALOGV("onMessageReceived kWhatPrepare");

            mSource->prepareAsync();
            break;
        }
```

对于本地播放源，mSource是GenericSource，继续跟踪：

```C++
void NuPlayer::GenericSource::prepareAsync() {
    Mutex::Autolock _l(mLock);
    ALOGV("prepareAsync: (looper: %d)", (mLooper != NULL));

    if (mLooper == NULL) {
        mLooper = new ALooper;
        mLooper->setName("generic");
        mLooper->start();

        mLooper->registerHandler(this);
    }

    sp<AMessage> msg = new AMessage(kWhatPrepareAsync, this);
    msg->post();
}
```

```C++
    switch (msg->what()) {
      case kWhatPrepareAsync:
      {
          onPrepareAsync();
          break;
      }
```

```c++
void NuPlayer::GenericSource::onPrepareAsync() {
    mDisconnectLock.lock();
    ALOGV("onPrepareAsync: mDataSource: %d", (mDataSource != NULL));

    // delayed data source creation
    if (mDataSource == NULL) {
        // set to false first, if the extractor
        // comes back as secure, set it to true then.
        mIsSecure = false;

        if (!mUri.empty()) {
            // 从网络创建MediaPlayer时才走此分支，此处省略
        } else {
            if (property_get_bool("media.stagefright.extractremote", true) &&
                    !PlayerServiceFileSource::requiresDrm(
                            mFd.get(), mOffset, mLength, nullptr /* mime */)) {
                sp<IBinder> binder =
                        defaultServiceManager()->getService(String16("media.extractor"));
                if (binder != nullptr) {
                    ALOGD("FileSource remote");
                    sp<IMediaExtractorService> mediaExService(
                            interface_cast<IMediaExtractorService>(binder));
                    sp<IDataSource> source;
                    mediaExService->makeIDataSource(base::unique_fd(dup(mFd.get())), mOffset, mLength, &source);
                    ALOGV("IDataSource(FileSource): %p %d %lld %lld",
                            source.get(), mFd.get(), (long long)mOffset, (long long)mLength);
                    if (source.get() != nullptr) {
                        mDataSource = CreateDataSourceFromIDataSource(source);
                    } else {
                        ALOGW("extractor service cannot make data source");
                    }
                } else {
                    ALOGW("extractor service not running");
                }
            }
            if (mDataSource == nullptr) {
                ALOGD("FileSource local");
                mDataSource = new PlayerServiceFileSource(dup(mFd.get()), mOffset, mLength);
            }
        }

        if (mDataSource == NULL) {
            ALOGE("Failed to create data source!");
            mDisconnectLock.unlock();
            notifyPreparedAndCleanup(UNKNOWN_ERROR);
            return;
        }
    }

    if (mDataSource->flags() & DataSource::kIsCachingDataSource) {
        mCachedSource = static_cast<NuCachedSource2 *>(mDataSource.get());
    }

    mDisconnectLock.unlock();

    // For cached streaming cases, we need to wait for enough
    // buffering before reporting prepared.
    mIsStreaming = (mCachedSource != NULL);

    // init extractor from data source
    status_t err = initFromDataSource();

    if (err != OK) {
        ALOGE("Failed to init from data source!");
        notifyPreparedAndCleanup(err);
        return;
    }

    if (mVideoTrack.mSource != NULL) {
        sp<MetaData> meta = getFormatMeta_l(false /* audio */);
        sp<AMessage> msg = new AMessage;
        err = convertMetaDataToMessage(meta, &msg);
        if(err != OK) {
            notifyPreparedAndCleanup(err);
            return;
        }
        notifyVideoSizeChanged(msg);
    }

    notifyFlagsChanged(
            // FLAG_SECURE will be known if/when prepareDrm is called by the app
            // FLAG_PROTECTED will be known if/when prepareDrm is called by the app
            FLAG_CAN_PAUSE |
            FLAG_CAN_SEEK_BACKWARD |
            FLAG_CAN_SEEK_FORWARD |
            FLAG_CAN_SEEK);

    finishPrepareAsync();

    ALOGV("onPrepareAsync: Done");
}
```

这块代码比较复杂，也不展开了，跟AudioTrack关系不大，后面有时间再研究下。

### 3.4.3 另一条分支。。。

再回到NuPlayerDriver::prepareAsync

```C++
status_t NuPlayerDriver::prepareAsync() {
    ALOGV("prepareAsync(%p)", this);
    Mutex::Autolock autoLock(mLock);

    switch (mState) {
        case STATE_UNPREPARED:
            mState = STATE_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->prepareAsync();
            return OK;
        case STATE_STOPPED:
            // this is really just paused. handle as seek to start
            mAtEOS = false;
            mState = STATE_STOPPED_AND_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->seekToAsync(0, MediaPlayerSeekMode::SEEK_PREVIOUS_SYNC /* mode */,
                    true /* needNotify */);
            return OK;
        default:
            return INVALID_OPERATION;
    };
}
```

当mState是STATE_STOPPED时，执行prepare()是会走到创建AudioTrack的流程的，具体流程见：

> https://blog.csdn.net/zhuyong006/article/details/86246540

这篇博客下面红框的部分可能是有误的，没有找到先prepare再stop再prepare的逻辑。

**只能暂时理解为，如果一个MediaPlayer执行过stop，再prepare的时候就会走到这个分支，直接创建AudioTrack。按这个理解，这个分支不是一个常见的场景，所以就不展开了，感兴趣可以参考上面的博客。**

综上，在没走到这个分支的情况下，调用prepare()是不会创建AudioTrack的

![image-20210921172130833](.\images\image-20210921172130833.png)

## 3.5 start

看下start，这次直奔主题，直接到NuPlayer::start

```C++
void NuPlayer::start() {
    (new AMessage(kWhatStart, this))->post();
}
```

```c++
        case kWhatStart:
        {
            ALOGV("kWhatStart");
            if (mStarted) {
                // do not resume yet if the source is still buffering
                if (!mPausedForBuffering) {
                    onResume();
                }
            } else {
                onStart();
            }
            mPausedByClient = false;
            break;
        }
```

来到NuPlayer::onStart()

```C++
void NuPlayer::onStart(int64_t startPositionUs, MediaPlayerSeekMode mode) {
    // 上面的代码都忽略，只看最后一行
    ...

    postScanSources();
}
```

```C++
void NuPlayer::postScanSources() {
    if (mScanSourcesPending) {
        return;
    }

    sp<AMessage> msg = new AMessage(kWhatScanSources, this);
    msg->setInt32("generation", mScanSourcesGeneration);
    msg->post();

    mScanSourcesPending = true;
}
```

```C++
case kWhatScanSources:
        {
            // 仅保留跟AudioTrack创建有关的
            if (mAudioSink != NULL && mAudioDecoder == NULL) {
                if (instantiateDecoder(true, &mAudioDecoder) == -EWOULDBLOCK) {
                    rescan = true;
                }
            }
        }
```

继续，来到instantiateDecoder()

```C++
status_t NuPlayer::instantiateDecoder(
        bool audio, sp<DecoderBase> *decoder, bool checkAudioModeChange) {
    if (audio) {
        sp<AMessage> notify = new AMessage(kWhatAudioNotify, this);
        ++mAudioDecoderGeneration;
        notify->setInt32("generation", mAudioDecoderGeneration);

        if (checkAudioModeChange) {
            determineAudioModeChange(format);
        }
    }
}
```

```C++
void NuPlayer::determineAudioModeChange(const sp<AMessage> &audioFormat) {
    if (canOffload) {
        if (!mOffloadAudio) {
            mRenderer->signalEnableOffloadAudio();
        }
        // open audio sink early under offload mode.
        tryOpenAudioSinkForOffload(audioFormat, audioMeta, hasVideo);
    } else {
        if (mOffloadAudio) {
            mRenderer->signalDisableOffloadAudio();
            mOffloadAudio = false;
        }
    }
}
```

```C++
void NuPlayer::tryOpenAudioSinkForOffload(
        const sp<AMessage> &format, const sp<MetaData> &audioMeta, bool hasVideo) {

    status_t err = mRenderer->openAudioSink(
            format, true /* offloadOnly */, hasVideo,
            AUDIO_OUTPUT_FLAG_NONE, &mOffloadAudio, mSource->isStreaming());
    if (err != OK) {
        // Any failure we turn off mOffloadAudio.
        mOffloadAudio = false;
    } else if (mOffloadAudio) {
        sendMetaDataToHal(mAudioSink, audioMeta);
    }
}
```

mRenderer对应NuPlayerRenderer：

```c++
status_t NuPlayer::Renderer::openAudioSink(
        const sp<AMessage> &format,
        bool offloadOnly,
        bool hasVideo,
        uint32_t flags,
        bool *isOffloaded,
        bool isStreaming) {
    sp<AMessage> msg = new AMessage(kWhatOpenAudioSink, this);
    msg->setMessage("format", format);
    msg->setInt32("offload-only", offloadOnly);
    msg->setInt32("has-video", hasVideo);
    msg->setInt32("flags", flags);
    msg->setInt32("isStreaming", isStreaming);

    sp<AMessage> response;
    status_t postStatus = msg->postAndAwaitResponse(&response);

    int32_t err;
    if (postStatus != OK || response.get() == nullptr || !response->findInt32("err", &err)) {
        err = INVALID_OPERATION;
    } else if (err == OK && isOffloaded != NULL) {
        int32_t offload;
        CHECK(response->findInt32("offload", &offload));
        *isOffloaded = (offload != 0);
    }
    return err;
}
```

kWhatOpenAudioSink处理线程：

```C++
        case kWhatOpenAudioSink:
        {
            sp<AMessage> format;
            CHECK(msg->findMessage("format", &format));

            int32_t offloadOnly;
            CHECK(msg->findInt32("offload-only", &offloadOnly));

            int32_t hasVideo;
            CHECK(msg->findInt32("has-video", &hasVideo));

            uint32_t flags;
            CHECK(msg->findInt32("flags", (int32_t *)&flags));

            uint32_t isStreaming;
            CHECK(msg->findInt32("isStreaming", (int32_t *)&isStreaming));

            status_t err = onOpenAudioSink(format, offloadOnly, hasVideo, flags, isStreaming);

            sp<AMessage> response = new AMessage;
            response->setInt32("err", err);
            response->setInt32("offload", offloadingAudio());

            sp<AReplyToken> replyID;
            CHECK(msg->senderAwaitsResponse(&replyID));
            response->postReply(replyID);

            break;
        }
```

onOpenAudioSink：

```C++
status_t NuPlayer::Renderer::onOpenAudioSink(
        const sp<AMessage> &format,
        bool offloadOnly,
        bool hasVideo,
        uint32_t flags,
        bool isStreaming) {

            err = mAudioSink->open(
                    sampleRate,
                    numChannels,
                    (audio_channel_mask_t)channelMask,
                    audioFormat,
                    0 /* bufferCount - unused */,
                    &NuPlayer::Renderer::AudioSinkCallback,
                    this,
                    (audio_output_flags_t)offloadFlags,
                    &offloadInfo);


}
```

这里的mAudioSink中的setDataSource_pre有完成设置，指向的是MediaPlayerService中的AudioOutput

```C++
status_t MediaPlayerService::AudioOutput::open(
        uint32_t sampleRate, int channelCount, audio_channel_mask_t channelMask,
        audio_format_t format, int bufferCount,
        AudioCallback cb, void *cookie,
        audio_output_flags_t flags,
        const audio_offload_info_t *offloadInfo,
        bool doNotReconnect,
        uint32_t suggestedFrameCount)
{
   
            t = new AudioTrack(
                    mStreamType,
                    sampleRate,
                    format,
                    channelMask,
                    frameCount,
                    flags,
                    NULL, // callback
                    NULL, // user data
                    0, // notification frames
                    mSessionId,
                    AudioTrack::TRANSFER_DEFAULT,
                    NULL, // offload info
                    mUid,
                    mPid,
                    mAttributes,
                    doNotReconnect,
                    targetSpeed,
                    mSelectedDeviceId,
                    mOpPackageName);

			mTrack = t;
}
```

综上，总算是找到了AudioTrack的创建位置，最终赋值给了MediaPlayerService的mTrack成员

# 4. AudioTrack(JAVA API)

Android面向应用开发者提供了MediaPlayer，AudioTrack，SoundPool等Java Api、提供AAudio等NDK接口用于播放声音。MediaPlayer可以播放MP3/FLAC/OGG等各种格式的声音，而AudioTrack只能播放解码后的PCM数据流。通过上一节“MediaPlayer到AudioTrack”，我们知道MediaPlayer也是会创建AudioTrack的。事实上，MediaPlayer内部会通过解码器先将音频输入解码，解码后通过AudioTrack播放。

本节主要介绍下AudioTrack的java api，并以此为契机说明下相关的几个音频概念。

## 4.1 构造方法

直接看AudioTrack.java的构造方法：

```JAVA
AudioTrack(int streamType, int sampleRateInHz, int channelConfig, int audioFormat, int bufferSizeInBytes, 
           int mode, int sessionId)
```

这个构造方法当前已经废弃了，google推荐使用AudioTrack::Builder()结合具备更丰富功能的AudioAttribute进行AudioTrack的初始化。

但方便起见，这里我们还使用这个构造方法。

下面，基于这个构造方法，逐个说明这些参数：

### 4.1.1 流类型

Android定义了很多流类型，以进行灵活的音频管理策略。例如，调节媒体音（STREAM_MUSIC）大小，不会影响到通话音（STREAM_VOICE_CALL）;再如，手机连接这蓝牙音箱的时候，我只把媒体音投放到蓝牙音箱，让家人们听音乐，而通话音仍保留在手机上，可以做到通话音乐两不误。

Android中的流类型（Stream type）定义在AudioManager.java中：

| 名称                              | 值                                   | 含义                       |
| --------------------------------- | ------------------------------------ | -------------------------- |
| AudioManager.STREAM_VOICE_CALL    | AudioSystem.STREAM_VOICE_CALL = 0    | 通话音                     |
| AudioManager.STREAM_SYSTEM        | AudioSystem.STREAM_SYSTEM = 1        | 系统音                     |
| AudioManager.STREAM_RING          | AudioSystem.STREAM_RING = 2          | 响铃音                     |
| AudioManager.STREAM_MUSIC         | AudioSystem.STREAM_MUSIC = 3         | 媒体音                     |
| AudioManager.STREAM_ALARM         | AudioSystem.STREAM_ALARM = 4         | 闹铃音                     |
| AudioManager.STREAM_NOTIFICATION  | AudioSystem.STREAM_NOTIFICATION = 5  | 通知音                     |
| AudioManager.STREAM_BLUETOOTH_SCO | AudioSystem.STREAM_BLUETOOTH_SCO = 6 | 蓝牙sco                    |
| AudioManager.STREAM_ENFORCED      | AudioSystem.STREAM_ENFORCED = 7      | 强制音（例如日本的拍照音） |
| AudioManager.STREAM_DTMF          | AudioSystem.STREAM_DTMF = 8          | 拨号盘按键音               |

虽然有很多流类型，但是很多是共享一个音量的。

### 4.1.2 采样率

> 采样：连续的时间信号进行周期性的扫描，变成时间上离散的瞬时信号的过程，采样遵循采样定理
>
> 采样率：每秒采样次数
>
> 采样定理（又名奈奎斯特定理）：当采样频率fs大于信号中最高频率fmax的2倍时(fs>2fmax)，采样之后的数字信号完整地保留了原始信号中的信息，也就是说可以不失真的恢复出原始的模拟信号。

人耳能听到的频率范围是20~20kHz，根据采样定理，fs>40kHz的时候就可以完整记录20kHz以下的音频信号，就可以完整地保存人耳能听到的音频数据。

常用的采样频率：

8kHz、11.025kHz、22.05kHz、16kHz、37.8kHz、44.1kHz、48kHz、96kHz、192kHz

AudioFormat.java中，定义了几个跟采样率有关的常量：

| 名称                           | 值     | 含义       |
| ------------------------------ | ------ | ---------- |
| AudioFormat.SAMPLE_RATE_HZ_MIN | 4000   | 最低采样率 |
| AudioFormat.SAMPLE_RATE_HZ_MAX | 192000 | 最高采样率 |

### 4.1.3 声道

> 声道(Sound Channel) 是指声音在录制或播放时在不同空间位置采集或回放的相互独立的[音频信号](https://baike.baidu.com/item/音频信号/3431469)，所以声道数也就是声音录制时的音源数量或回放时相应的扬声器数量。

声道类型包含单声道、立体声、5.1声道、7.1声道

Android中的声道数（Sound Channel）定义在AudioFormat.java中：

| 名称                           | 值                                                 | 含义   |
| ------------------------------ | -------------------------------------------------- | ------ |
| AudioFormat.CHANNEL_OUT_MONO   | AudioFormat.CHANNEL_OUT_FRONT_LEFT = 0x4           | 单声道 |
| AudioFormat.CHANNEL_OUT_STEREO | (CHANNEL_OUT_FRONT_LEFT \|CHANNEL_OUT_FRONT_RIGHT) | 立体声 |
| 其他（略）                     |                                                    |        |

注意到AudioFormat中还定义了CHANNEL_IN_MONO、CHANNEL_IN_STEREO等，这些用于录音场景（AudioRecorder）。

### 4.1.4 位宽

> 位宽（Audio Format）又称采样位数、采样精度，代表采样数据的精确程度。位宽越大，采样数据的解析度/分辨率越高，声音也更自然。
>
> 例如，8位代表音乐信息有2的8次方，也就是256个精度单位。16位有64k个精度单位，前者会造成精度丢失。

Android中的位宽（Audio Format）定义在AudioFormat.java中：

| 名称                           | 值   | 含义          |
| ------------------------------ | ---- | ------------- |
| AudioFormat.ENCODING_INVALID   | 0    | 非法位宽      |
| AudioFormat.ENCODING_DEFAULT   | 1    | 默认位宽      |
| AudioFormat.ENCODING_PCM_16BIT | 2    | 16位/每采样点 |
| AudioFormat.ENCODING_PCM_32BIT | 3    | 32位/每采样点 |

### 4.1.5 BufferSizeInBytes

> BufferSizeInBytes是最重要的一个参数，它配置的是AudioTrack内部音频缓冲区的大小，它是声音能正常播放的最低保障。
>
> BufferSizeInBytes跟AudioTrack的mode也有关。
>
> 当处于MODE_STATIC模式时，BufferSizeInBytes是待播放的采样数据的总大小
>
> 当处于MODE_STREAM模式，代表缓冲区最小大小，使用getMinBufferSize()计算

AudioTrack提供了一个帮开发者确认最低内部缓冲区大小的方法，原型如下：

```java
int getMinBufferSize(int sampleRateInHz, int channelConfig, int audioFormat) {
	return native_get_min_buff_size(sampleRateInHz, channelCount, audioFormat);
}
```

从传参可以看到，最小音频缓冲区大小，是跟上面提到的采样率、声道和位宽相关的。

继续查看JNI层：

```C++
// 查看JNI
static jint android_media_AudioTrack_get_min_buff_size(JNIEnv *env,  jobject thiz,
    jint sampleRateInHertz, jint channelCount, jint audioFormat) {

    size_t frameCount;
    const status_t status = AudioTrack::getMinFrameCount(&frameCount, AUDIO_STREAM_DEFAULT,
            sampleRateInHertz);
    if (status != NO_ERROR) {
        ALOGE("AudioTrack::getMinFrameCount() for sample rate %d failed with status %d",
                sampleRateInHertz, status);
        return -1;
    }
    const audio_format_t format = audioFormatToNative(audioFormat);
    if (audio_has_proportional_frames(format)) {
        const size_t bytesPerSample = audio_bytes_per_sample(format);
        // frameCount：通过采样率计算得到的最低音频帧数
        // channelCount：声道
        // bytesPerSample：通过位宽计算得到的每帧字节数
        return frameCount * channelCount * bytesPerSample;
    } else {
        return frameCount;
    }
}
```

$$
最小缓冲区大小
	= 最小采样时间 * 采样率 * 声道数 * 位宽
    = 最小帧数 * 声道数 * 每帧字节数
$$

### 4.1.6 mode

AudioTrack有两种数据传输模式，定义在AudioTrack.java

| MODE                   | 含义                                                         |
| ---------------------- | ------------------------------------------------------------ |
| AudioTrack.MODE_STATIC | 应用进程将回放数据一次性付给 AudioTrack，适用于数据量小、时延要求高的场景 |
| AudioTrack.MODE_STREAM | 用进程需要持续调用 write() 写数据到 FIFO，写数据时有可能遭遇阻塞（等待 AudioFlinger::PlaybackThread 消费之前的数据），基本适用所有的音频场景 |



两种mode下创建AudioTrack对象的区别：

> MODE_STATIC下，bufferSizeInBytes就是待播放文件的大小：

```java
//file 就是需要播放的音频文件，这里的buffersize就是文件的大小
audioTrack = new AudioTrack(AudioManager.STREAM_MUSIC,
        44100, AudioFormat.CHANNEL_OUT_STEREO,
        AudioFormat.ENCODING_PCM_16BIT, (int) file.length(), AudioTrack.MODE_STATIC);
```

> MODE_STREAM下，bufferSizeInBytes需要通过getMinBufferSize()计算

```java
 bufferSize = AudioTrack.getMinBufferSize(44100, AudioFormat.CHANNEL_OUT_STEREO, AudioFormat.ENCODING_PCM_16BIT);
        audioTrack = new AudioTrack(AudioManager.STREAM_MUSIC,
                44100, AudioFormat.CHANNEL_OUT_STEREO, AudioFormat.ENCODING_PCM_16BIT, bufferSize, AudioTrack.MODE_STREAM);
```

## 4.2 关键成员

### 4.2.1 mState

一般结合getState()方法，用于在AudioTrack构造方法执行后，判断是否初始化成功

```java
        mAudioTrack = new AudioTrack(streamType,sampleRateInHz,channelConfig,audioFormat,mMinBufferSize,DEFAULT_PLAY_MODE);
        if (mAudioTrack.getState() == AudioTrack.STATE_UNINITIALIZED) {
            Log.e(TAG, "AudioTrack initialize fail !");
            return false;
        }   
```

mState有三个状态：

| 名称                             | 值   | 含义                                                         |
| -------------------------------- | ---- | ------------------------------------------------------------ |
| AudioFormat.STATE_UNINITIALIZED  | 0    | AudioTrack未成功初始化                                       |
| AudioFormat.STATE_INITIALIZED    | 1    | AudioTrack成功初始化                                         |
| AudioFormat.STATE_NO_STATIC_DATA | 2    | 当前是使用 MODE_STATIC ，但是还没往缓冲区中写入数据。当接收数据之后会变为 STATE_INITIALIZED 状态 |

![image-20211002111338214](.\images\image-20211002111338214.png)

### 4.2.2 mPlayState

播放状态

| 名称                          | 值   | 含义 |
| ----------------------------- | ---- | ---- |
| AudioFormat.PLAYSTATE_STOPPED | 1    | 停止 |
| AudioFormat.PLAYSTATE_PAUSED  | 2    | 暂停 |
| AudioFormat.PLAYSTATE_PLAYING | 3    | 播放 |

### 4.2.3 mDataLoadMode

保存mode，有两个值：MODE_STATIC，MODE_STREAM

## 4.3 关键方法

### 4.3.1 写数据（write）

```JAVA
int write(@NonNull byte[] audioData, int offsetInBytes, int sizeInBytes,
            @WriteMode int writeMode)
```

参数含义：

| 名称          | 含义               |
| ------------- | ------------------ |
| audioData     | 待写入数据         |
| offsetInBytes | 待写入数据起始位置 |
| sizeInBytes   | 待写入数据长度     |
| writeMode     | 写入模式           |

MODE_STATIC模式下，调用write()之后，AudioTrack的mState就会从STATE_NO_STATIC_DATA切换到STATE_INITIALIZED，紧接着就可以调用play()播放了。此外，MODE_STATIC模式下，AudioTrack是直接进行memcopy的，耗时短，所以设计为同步方法。

MODE_STREAM模式下，write()可能会阻塞，需要在子线程中执行write()。

> 详细内容会在AudioTrack（native层）详细说明，本节只说明AudioTrack java层API的使用方法。

### 4.3.2 播放（play）

MODE_STATIC模式下，write()完毕可以直接play()进行播放

```java
//先将所有的数据写入到缓冲区
write(...)
//然后在播放
play(..)
```

MODE_STREAM模式下，先调用play()，然后子线程中不断write()写入数据

```java
paly(...)

new Thread() {
    public void run() {
        //一系列的 write 操作
        `write(...)`
    }
    
}.start();
```

### 4.3.3 停止播放（stop）

> 对于 `MODE_STREAM` 模式，如果单是调用 stop 方法， AudioTrack 会等待缓冲的最后一帧数据播放完毕之后，才会停止，如果需要立即停止，那么就需要调用 `pause` 然后调用 `flush` 这两个方法，那么 AudioTrack 就是丢缓冲区中剩余的数据。

```java
void stop ()
```

### 4.3.4 暂停播放（pause）

> 暂停播放，但是缓冲区中没有被播放的数据不会被舍弃，调用 play 方法即可接着播放

```java
void pause ()
```

### 4.3.5 刷新（flush）

> 刷新正在排队播放的音频数据，调用该方法会将写入到缓冲区但没有被播放的音频数据都会被丢弃。如果是非 STREAM 或者没有执行 pasuse 或者 stop 将不会有任何效果。

```java
void flush()
```

### 4.3.6 释放（release）

> 释放本地 AudioTrack 对象。

```java
void release ()
```

## 4.4 代码示例

### 4.4.1 静态播放示例

```java
// ************ 静态播放模式 ************ 
// 直接获取文件大小
InputStream in = getResources().openRawResource(R.raw.ding);
try {
   try {
       ByteArrayOutputStream out = new ByteArrayOutputStream();
       for (int b; (b = in.read()) != -1; ) {
           out.write(b);
       }
       audioData = out.toByteArray();
   } finally {
       in.close();
   }
} catch (IOException ioe) {
   ioe.printStackTrace();
   Log.d(TAG, "读取数据失败！");
}
//构造AudioTrack对象，写入数据并播放
audioTrack = new AudioTrack(
new AudioAttributes.Builder()
        .setUsage(AudioAttributes.USAGE_MEDIA)
        .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
        .build(),
new AudioFormat.Builder().setSampleRate(22050)
        .setEncoding(AudioFormat.ENCODING_PCM_8BIT)
        .setChannelMask(AudioFormat.CHANNEL_OUT_MONO)
        .build(),
audioData.length,
AudioTrack.MODE_STATIC,
AudioManager.AUDIO_SESSION_ID_GENERATE);
audioTrack.write(audioData, 0, audioData.length);
if(audioTrack.getState() == AudioTrack.STATE_UNINITIALIZED){
    Toast.makeText(this,"AudioTrack初始化失败！",Toast.LENGTH_SHORT).show();
    return;
} 
audioTrack.play();
```

### 4.4.2 流播放示例

```java
// ************ 流播放 ************ 
final int minBufferSize = AudioTrack.getMinBufferSize(SAMPLE_RATE_INHZ, AudioFormat.CHANNEL_OUT_MONO, AUDIO_FORMAT);
// 创建 AudioTrack 对象
audioTrack = new AudioTrack(
 new AudioAttributes.Builder()
         .setUsage(AudioAttributes.USAGE_MEDIA)
         .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
         .build(),
 new AudioFormat.Builder().setSampleRate(SAMPLE_RATE_INHZ)
         .setEncoding(AUDIO_FORMAT)
         .setChannelMask(AudioFormat.CHANNEL_OUT_MONO)
         .build(),
 minBufferSize,
 AudioTrack.MODE_STREAM,
 AudioManager.AUDIO_SESSION_ID_GENERATE
);
// 检查初始化是否成功
if(audioTrack.getState() == AudioTrack.STATE_UNINITIALIZED){
    Toast.makeText(this,"AudioTrack初始化失败！",Toast.LENGTH_SHORT).show();
    return;
} 
// 播放
audioTrack.play();
//子线程中文件流写入
workHandler.post(new Runnable() {
   @Override
   public void run() {
       try {
           final File file = new File(getExternalFilesDir(Environment.DIRECTORY_MUSIC), "test.pcm");
           FileInputStream fileInputStream = new FileInputStream(file);
           byte[] tempBuffer = new byte[minBufferSize];
           while (fileInputStream.available() > 0) {
               int readCount = fileInputStream.read(tempBuffer);
               if (readCount == AudioTrack.ERROR_INVALID_OPERATION ||
                       readCount == AudioTrack.ERROR_BAD_VALUE) {
                   continue;
               }
               if (readCount != 0 && readCount != -1) {
                   audioTrack.write(tempBuffer, 0, readCount);
               }
           }
           fileInputStream.close();
       } catch (IOException ioe) {
           ioe.printStackTrace();
       }
   }
});
```

### 4.4.3 停止播放

```java
// 停止线程
handlerThread.quit();
workHandler.removeCallbacksAndMessages(null);
if(audioTrack.getState() != AudioTrack.STATE_UNINITIALIZED){
    audioTrack.stop();
    audioTrack.release();
}
```

# 5. AudioTrack(源码走读)

native层的接口位于AudioTrack.cpp，native层接口所处的位置可以用下图说明：

![image-20211003203046859](.\images\image-20211003203046859.png)



涉及到走AudioTrack进行音频播放的，包括MediaPlayer.java、AudioTrack.java，都需要通过AudioTrack.cpp走binder与audioserver进程进行通信，进而实现播放过程。

## 5.1 关键Binder接口

AudioTrack.cpp与audioserver之间的关键Binder及定义位置如下：

| 类           | 位置                              |
| ------------ | --------------------------------- |
| IAudioTrack  | IAudioTrack.h                     |
| BnAudioTrack | IAudioTrack.h                     |
| TrackHandle  | AudioFlinger.h / AudioFlinger.cpp |
| BpAudioTrack | AudioTrack.cpp                    |

