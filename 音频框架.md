# 音频框架

## 1. 概述

关键类位置：

| 名称                 | 路径                                                 |
| -------------------- | ---------------------------------------------------- |
| audioserver.rc       | frameworks/av/media/audioserver/audioserver.rc       |
| main_audioserver.cpp | frameworks/av/media/audioserver/main_audioserver.cpp |
| processState.cpp     | frameworks/native/libs/binder                        |
| IServiceManager.cpp  | frameworks/native/libs/binder                        |
|                      |                                                      |
|                      |                                                      |
|                      |                                                      |
|                      |                                                      |
|                      |                                                      |

关键so/exe/jar源文件位置：

| 名称                     | 路径                                                 |
| ------------------------ | ---------------------------------------------------- |
| audioserver.exe          | frameworks/av/media/audioserver/                     |
| libaudioservice.so       |                                                      |
| libaudioflinger.so       | frameworks/av/services/audioflinger/                 |
| libaudiopolicyservice.so | frameworks/av/services/audiopolicy/services/service/ |



audioserver依赖的共享库：

![image-20210921102707057](.\images\image-20210921102707057.png)

## 2 audioserver进程启动

启动配置文件：audioserver.rc：

```
frameworks/av/media/audioserver/audioserver.rc

service audioserver /system/bin/audioserver
    class core
    user audioserver
    # media gid needed for /dev/fm (radio) and for /data/misc/media (tee)
    group audio camera drmrpc media mediadrm net_bt net_bt_admin net_bw_acct wakelock
    capabilities BLOCK_SUSPEND
    ioprio rt 4
    task_profiles ProcessCapacityHigh HighPerformance
    onrestart restart vendor.audio-hal
    onrestart restart vendor.audio-hal-4-0-msd
    # Keep the original service names for backward compatibility
    onrestart restart vendor.audio-hal-2-0
    onrestart restart audio-hal-2-0
```

启动入口位于main_audioserver.cpp

```C++
frameworks/av/media/audioserver/main_audioserver.cpp

int main(int argc __unused, char **argv)
{
    // TODO: update with refined parameters
    limitProcessMemory(
        "audio.maxmem", /* "ro.audio.maxmem", property that defines limit */
        (size_t)512 * (1 << 20), /* SIZE_MAX, upper limit in bytes */
        20 /* upper limit as percentage of physical RAM */);

    signal(SIGPIPE, SIG_IGN);

#if 1
    // FIXME See bug 165702394 and bug 168511485
    const bool doLog = false;
#else
    bool doLog = (bool) property_get_bool("ro.test_harness", 0);
#endif

    pid_t childPid;
    if (doLog && (childPid = fork()) != 0) {
        // 因为doLog是false，这部分代码省略
        ......        
    } else {
        // all other services
        if (doLog) {
        // 因为doLog是false，这部分代码省略
        ......    
        }
        
        // 核心代码start
        android::hardware::configureRpcThreadpool(4, false /*callerWillJoin*/);
        sp<ProcessState> proc(ProcessState::self());
        sp<IServiceManager> sm = defaultServiceManager();
        ALOGI("ServiceManager: %p", sm.get());
        AudioFlinger::instantiate();
        AudioPolicyService::instantiate();

        // AAudioService should only be used in OC-MR1 and later.
        // And only enable the AAudioService if the system MMAP policy explicitly allows it.
        // This prevents a client from misusing AAudioService when it is not supported.
        aaudio_policy_t mmapPolicy = property_get_int32(AAUDIO_PROP_MMAP_POLICY,
                                                        AAUDIO_POLICY_NEVER);
        if (mmapPolicy == AAUDIO_POLICY_AUTO || mmapPolicy == AAUDIO_POLICY_ALWAYS) {
            AAudioService::instantiate();
        }

        ProcessState::self()->startThreadPool();
        IPCThreadState::self()->joinThreadPool();
        // 核心代码end
    }
}
```

抽取核心代码：

```C++
frameworks/av/media/audioserver/main_audioserver.cpp

int main(int argc __unused, char **argv)
{   
    // 一、获得一个ProcessState的实例
    sp<ProcessState> proc(ProcessState::self());
    // 二、audioServer进程作为ServiceManager的客户端，需要向ServiceManager注册服务
    // 调用defaultServiceManager()得到一个IserviceManager
    sp<IServiceManager> sm = defaultServiceManager();
    // 三、初始化音频系统的AudioFlinger服务
    AudioFlinger::instantiate();
    // 四、初始化音频系统的AudioPolicyService服务
    AudioPolicyService::instantiate();

    // 五、按需初始化音频系统的AAudioService服务
    aaudio_policy_t mmapPolicy = property_get_int32(AAUDIO_PROP_MMAP_POLICY,
    AAUDIO_POLICY_NEVER);
    if (mmapPolicy == AAUDIO_POLICY_AUTO || mmapPolicy == AAUDIO_POLICY_ALWAYS) {
    AAudioService::instantiate();
    }

    // 六、创建一个线程池
    ProcessState::self()->startThreadPool();
    // 将自己加入该线程池
    IPCThreadState::self()->joinThreadPool();
    }
}
```

上面的核心步骤会分别展开说明

### 2.1 ProcessState::self

主要针对这行代码展开说明：

```C++
// main_audioserver.cpp
	// 一、获得一个ProcessState的实例
    sp<ProcessState> proc(ProcessState::self());
```

```C++
// ProcessState.cpp

sp<ProcessState> ProcessState::self()
{
    return init(kDefaultDriver, false);
}

// 通过std::once_flag和std::call_once实现单例，即sp<ProcessState>::make(driver)只调用一次
// 相应的，gProcess也只初始化一次
sp<ProcessState> ProcessState::init(const char *driver, bool requireDefault)
{
    [[clang::no_destroy]] static sp<ProcessState> gProcess;
    [[clang::no_destroy]] static std::mutex gProcessMutex;

    if (driver == nullptr) {
        std::lock_guard<std::mutex> l(gProcessMutex);
        return gProcess;
    }

    [[clang::no_destroy]] static std::once_flag gProcessOnce;
    std::call_once(gProcessOnce, [&](){
        if (access(driver, R_OK) == -1) {
            ALOGE("Binder driver %s is unavailable. Using /dev/binder instead.", driver);
            driver = "/dev/binder";
        }

        std::lock_guard<std::mutex> l(gProcessMutex);
        gProcess = sp<ProcessState>::make(driver);
    });

    return gProcess;
}
```

sp<ProcessState>智能指针的make函数，实际上是执行了ProcessState的构造函数，然后返回智能指针

```C++
// StrongPointer.h
template <typename T>
template <typename... Args>
sp<T> sp<T>::make(Args&&... args) {
    T* t = new T(std::forward<Args>(args)...);
    sp<T> result;
    result.m_ptr = t;
    t->incStrong(t);  // bypass check_not_on_stack for heap allocation
    return result;
}
```

查看ProcessState的构造函数

```C++
// ProcessState.cpp

ProcessState::ProcessState(const char *driver)
    : mDriverName(String8(driver))
        // 打开/dev/binder这个设备，这是android在内核中专门用于完成进程间通信而设置的一个虚拟设备。
    , mDriverFD(open_driver(driver))
    , mVMStart(MAP_FAILED)
    , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER)
    , mThreadCountDecrement(PTHREAD_COND_INITIALIZER)
    , mExecutingThreadsCount(0)
    , mWaitingForThreads(0)
    , mMaxThreads(DEFAULT_MAX_BINDER_THREADS)
    , mStarvationStartTimeMs(0)
    , mThreadPoolStarted(false)
    , mThreadPoolSeq(1)
    , mCallRestriction(CallRestriction::NONE)
{

    if (mDriverFD >= 0) {
        // mmap the binder, providing a chunk of virtual address space to receive transactions.
        mVMStart = mmap(nullptr, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0);
        if (mVMStart == MAP_FAILED) {
            // *sigh*
            ALOGE("Using %s failed: unable to mmap transaction memory.\n", mDriverName.c_str());
            close(mDriverFD);
            mDriverFD = -1;
            mDriverName.clear();
        }
    }
}
```

总结，ProcessState::self做了三件事：

- 打开/dev/binder设备，这就相当于与内核的Binder驱动有了交互的通道。
- 对返回的fd使用mmap，这样Binder驱动就会分配一块内存来接收数据。
- 由于ProcessState的惟一性，因此一个进程只打开设备一次。

### 2.2 defaultServiceManager

主要针对这行代码展开说明：

```C++
// 二、audioServer进程作为ServiceManager的客户端，需要向ServiceManager注册服务
    // 调用defaultServiceManager()得到一个IserviceManager
    sp<IServiceManager> sm = defaultServiceManager();
```

defaultServiceManager()函数位于IServiceManager.cpp：

```C++
// IServiceManager.cpp

using AidlServiceManager = android::os::IServiceManager;

[[clang::no_destroy]] static std::once_flag gSmOnce;
[[clang::no_destroy]] static sp<IServiceManager> gDefaultServiceManager;

sp<IServiceManager> defaultServiceManager()
{
    // 可以看到也是个单例
    std::call_once(gSmOnce, []() {
        sp<AidlServiceManager> sm = nullptr;
        while (sm == nullptr) {
            sm = interface_cast<AidlServiceManager>(ProcessState::self()->getContextObject(nullptr));
            if (sm == nullptr) {
                ALOGE("Waiting 1s on context object on %s.", ProcessState::self()->getDriverName().c_str());
                sleep(1);
            }
        }

        gDefaultServiceManager = sp<ServiceManagerShim>::make(sm);
    });

    return gDefaultServiceManager;
}
```

//  TODO

https://www.kancloud.cn/alex_wsc/android_depp/412925

### AudioFlinger::instantiate

### AudioPolicyService::instantiate

### AAudioServcei::instantiate

### start&joinThreadPool

## 3. MediaPlayer到AudioTrack

这一节重点梳理下应用层调用MediaPlayer后，是如何一步步创建AudioTrack的。

### 3.1 应用层代码

简单的使用MediaPlayer的播放流程，播放assets下的音频文件。

```java
package com.colin.mediaplayerdemo;

import ...

public class MainActivity extends AppCompatActivity implements View.OnClickListener {
    private Button mPlay;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        initView();
    }

    private void initView() {
        mPlay = findViewById(R.id.play);
        mPlay.setOnClickListener(this);
    }

    @Override
    public void onClick(View v) {
        switch (v.getId()) {
            case R.id.play:
                try {
                    MediaPlayer mp = new MediaPlayer();
                    mp.setOnPreparedListener(mediaPlayer -> mediaPlayer.start());
                    AssetManager assetMg = this.getApplicationContext().getAssets();
                    AssetFileDescriptor fileDescriptor = null;
                    fileDescriptor = assetMg.openFd("music.mp3");
                    mp.setDataSource(fileDescriptor.getFileDescriptor(), fileDescriptor.getStartOffset(), fileDescriptor.getLength());
                    mp.prepare();
                } catch (IOException e) {
                    e.printStackTrace();
                }
                break;
            default:
                break;
        }
    }
}
```

### 3.2 MediaPlayer的调用流程

简单看下MediaPlayer的调用流程

![image-20210921132855725](.\images\image-20210921132855725.png)

实际上，不仅仅是MediaPlayer，其他很多地方也是类似的。上面通过jni透传到native的就不关注了，主要关注下binder的部分。

### 3.3 setDataSource

setDataSource为例，看下mediaplayer.cpp是怎么调用服务侧的：

> mediaplayer

```c++
status_t MediaPlayer::setDataSource(int fd, int64_t offset, int64_t length)
{
    ALOGV("setDataSource(%d, %" PRId64 ", %" PRId64 ")", fd, offset, length);
    status_t err = UNKNOWN_ERROR;
    // 获取IMediaPlayerService，实际上是BpMediaPlayerService
    const sp<IMediaPlayerService> service(getMediaPlayerService());
    if (service != 0) {
        // 调用BpMediaPlayerService的函数，返回获取IMediaPlayer,实际上拿到的是BpMediaPlayer
        sp<IMediaPlayer> player(service->create(this, mAudioSessionId, mOpPackageName));
        if ((NO_ERROR != doSetRetransmitEndpoint(player)) ||
            // 调用IMediaPlayer（BpMediaPlayer）的同名方法
            (NO_ERROR != player->setDataSource(fd, offset, length))) {
            player.clear();
        }
        err = attachNewPlayer(player);
    }
    return err;
}
```

BpMediaPlayer最终会调用到BnMediaPlayer子类，也就是MediaPlayerService::Client的同名方法：

> 有兴趣可以看下MediaPlayer这块的binder接口定义，包括IMediaPlayerClient，IMediaPlayer，IMediaPlayerService。这里就不展开了。

> MediaPlayerService::Client

```c++
status_t MediaPlayerService::Client::setDataSource(int fd, int64_t offset, int64_t length)
{
	// 获取文件类型
    player_type playerType = MediaPlayerFactory::getPlayerType(this,
                                                               fd,
                                                               offset,
                                                               length);
    // 预处理，拿到MediaPlayerBase对象
    sp<MediaPlayerBase> p = setDataSource_pre(playerType);
    if (p == NULL) {
        return NO_INIT;
    }

    // 执行MediaPlayerBase的setDataSource
    return mStatus = setDataSource_post(p, p->setDataSource(fd, offset, length));
}
```

#### 3.3.1 setDataSource_pre

不同的文件对应不同的播放器类，播放器类的公共父类为MediaPlayerBase，所以setDataSource_pre类似于一个生产MediaPlayerBase的工厂，传参是具体的player类型，下面看下这个工厂是如何实现的:

```C++
sp<MediaPlayerBase> MediaPlayerService::Client::setDataSource_pre(
        player_type playerType)
{

    sp<MediaPlayerBase> p = createPlayer(playerType);
    if (p == NULL) {
        return p;
    }

    if (!p->hardwareOutput()) {
        mAudioOutput = new AudioOutput(mAudioSessionId, IPCThreadState::self()->getCallingUid(),
                mPid, mAudioAttributes, mAudioDeviceUpdatedListener, mOpPackageName);
        static_cast<MediaPlayerInterface*>(p.get())->setAudioSink(mAudioOutput);
    }

    return p;
}
```

看下cratePlayer:

```C++
sp<MediaPlayerBase> MediaPlayerService::Client::createPlayer(player_type playerType)
{
    sp<MediaPlayerBase> p = getPlayer();
    if ((p != NULL) && (p->playerType() != playerType)) {
        ALOGV("delete player");
        p.clear();
    }
    if (p == NULL) {
        // getPlayer()返回mPlayer成员，此时必然为null，走到本分支
        p = MediaPlayerFactory::createPlayer(playerType, mListener, mPid);
    }

    if (p != NULL) {
        p->setUID(mUid);
    }

    return p;
}
```

ok，看下MediaPlayerFactory这个工厂类：

> MediaPlayerFactory

```C++
sp<MediaPlayerBase> MediaPlayerFactory::createPlayer(
        player_type playerType,
        const sp<MediaPlayerBase::Listener> &listener,
        pid_t pid) {
    sp<MediaPlayerBase> p;
    IFactory* factory;

    // 核心在于sFactoryMap是什么时候初始化的
    factory = sFactoryMap.valueFor(playerType);
    CHECK(NULL != factory);
    p = factory->createPlayer(pid);

    return p;
}
```

看下sFactoryMap的写入时机，找到一个函数：

```C++
status_t MediaPlayerFactory::registerFactory_l(IFactory* factory,
                                               player_type type) {

    if (sFactoryMap.add(type, factory) < 0) {
        ALOGE("Failed to register MediaPlayerFactory of type %d, failed to add"
              " to map.", type);
        return UNKNOWN_ERROR;
    }

    return OK;
}
```

搜索registerFactory_l的调用，找到两个核心的位置：

> 位置1：MediaPlayerFactory::registerFactory

```C++
status_t MediaPlayerFactory::registerFactory(IFactory* factory,
                                             player_type type) {
    Mutex::Autolock lock_(&sLock);
    return registerFactory_l(factory, type);
}
```

> 位置2：MediaPlayerFactory::registerBuiltinFacotories

```C++
void MediaPlayerFactory::registerBuiltinFactories() {
    Mutex::Autolock lock_(&sLock);

    if (sInitComplete)
        return;

    IFactory* factory = new NuPlayerFactory();
    if (registerFactory_l(factory, NU_PLAYER) != OK)
        delete factory;
    factory = new TestPlayerFactory();
    if (registerFactory_l(factory, TEST_PLAYER) != OK)
        delete factory;

    sInitComplete = true;
}
```

到这里可以大概知道至少有两个Player：

> NuPlayerFactory和TestPlayerFactory

后者明显是测试用的，实际上，手机厂商可以拓展registerBuiltinFactories()，从而实现自己的Player

> 那么问题来了，sFactoryMap中有那么多的Factory，MediaPlayerFactory是如何知道返回哪个Factory的呢

直接看下IFactory接口：

```C++
    class IFactory {
      public:
        virtual ~IFactory() { }

        virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                                   const char* /*url*/,
                                   float /*curScore*/) { return 0.0; }

        virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                                   int /*fd*/,
                                   int64_t /*offset*/,
                                   int64_t /*length*/,
                                   float /*curScore*/) { return 0.0; }

        virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                                   const sp<IStreamSource> &/*source*/,
                                   float /*curScore*/) { return 0.0; }

        virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                                   const sp<DataSource> &/*source*/,
                                   float /*curScore*/) { return 0.0; }

        virtual sp<MediaPlayerBase> createPlayer(pid_t pid) = 0;
    };
```

可以看到IFactory接口中定义了两个函数，一个是createPlayer()，也就是用来创建我们的MediaPlayerBase播放器的。另一个叫scoreFactory()，顾名思义，这个函数可以计算一个分数。

> 实际上，MediaPlayerFactory会根据媒体文件的类型，调用sFactoryMap中，每个Factory的scoreFactory()函数，返回得分最高的Factory。

这里返回的是NuPlayerFactory：

```C++
class NuPlayerFactory : public MediaPlayerFactory::IFactory {
  public:
    virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                               const char* url,
                               float curScore) {
        static const float kOurScore = 0.8;

        if (kOurScore <= curScore)
            return 0.0;

        if (!strncasecmp("http://", url, 7)
                || !strncasecmp("https://", url, 8)
                || !strncasecmp("file://", url, 7)) {
            size_t len = strlen(url);
            if (len >= 5 && !strcasecmp(".m3u8", &url[len - 5])) {
                return kOurScore;
            }

            if (strstr(url,"m3u8")) {
                return kOurScore;
            }

            if ((len >= 4 && !strcasecmp(".sdp", &url[len - 4])) || strstr(url, ".sdp?")) {
                return kOurScore;
            }
        }

        if (!strncasecmp("rtsp://", url, 7)) {
            return kOurScore;
        }

        return 0.0;
    }

    virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                               const sp<IStreamSource>& /*source*/,
                               float /*curScore*/) {
        return 1.0;
    }

    virtual float scoreFactory(const sp<IMediaPlayer>& /*client*/,
                               const sp<DataSource>& /*source*/,
                               float /*curScore*/) {
        // Only NuPlayer supports setting a DataSource source directly.
        return 1.0;
    }

    virtual sp<MediaPlayerBase> createPlayer(pid_t pid) {
        ALOGV(" create NuPlayer");
        return new NuPlayerDriver(pid);
    }
};
```

NuPlayerFactory创建的MediaPlayerBase是：NuPlayerDriver

#### 3.3.2 setDataSource_post

继续看下setDataSource_post：

```C++
status_t MediaPlayerService::Client::setDataSource(int fd, int64_t offset, int64_t length)
{
	// 获取文件类型
    player_type playerType = MediaPlayerFactory::getPlayerType(this,
                                                               fd,
                                                               offset,
                                                               length);
    // 预处理，拿到MediaPlayerBase对象
    sp<MediaPlayerBase> p = setDataSource_pre(playerType);
    if (p == NULL) {
        return NO_INIT;
    }

    // 执行MediaPlayerBase的setDataSource
    return mStatus = setDataSource_post(p, p->setDataSource(fd, offset, length));
}
```

一步步来，首先是NuPlayerDriver::setDataSource()

> NuPlayerDriver::setDataSource

```C++
status_t NuPlayerDriver::setDataSource(int fd, int64_t offset, int64_t length) {
    ALOGV("setDataSource(%p) file(%d)", this, fd);
    Mutex::Autolock autoLock(mLock);

    if (mState != STATE_IDLE) {
        return INVALID_OPERATION;
    }

    mState = STATE_SET_DATASOURCE_PENDING;

    mPlayer->setDataSourceAsync(fd, offset, length);

    while (mState == STATE_SET_DATASOURCE_PENDING) {
        mCondition.wait(mLock);
    }

    return mAsyncResult;
}
```

OK，看来需要先搞清楚NuPlayerDriver::mPlayer是啥，啥时候初始化的：

```C++
// mPlayer是啥？
const sp<NuPlayer> mPlayer;

// mPlayer啥时候初始化的？
NuPlayerDriver::NuPlayerDriver(pid_t pid)
    : mState(STATE_IDLE),
      ...
      mPlayer(new NuPlayer(pid, mMediaClock)),
	  ...
```

好吧，猜测这个NuPlayerDriver也只是套壳，实际上执行功能的是NuPlayer

继续看NuPlayer::setDataSourceAsync()，顾名思义，这是个异步操作：

```c++
void NuPlayer::setDataSourceAsync(int fd, int64_t offset, int64_t length) {
    sp<AMessage> msg = new AMessage(kWhatSetDataSource, this);

    sp<AMessage> notify = new AMessage(kWhatSourceNotify, this);

    sp<GenericSource> source =
            new GenericSource(notify, mUIDValid, mUID, mMediaClock);

    status_t err = source->setDataSource(fd, offset, length);

    if (err != OK) {
        ALOGE("Failed to set data source!");
        source = NULL;
    }

    msg->setObject("source", source);
    msg->post();
    mDataSourceType = DATA_SOURCE_TYPE_GENERIC_FD;
}
```

emmm，看到了AMessage，应该是跟java侧的Handler类似的功能吧，姑且先理解为，NuPlayer把setDataSource的任务post到子线程去做了。具体关于AMessage，后面有时间再研究。

注意到有两个AMessage，首先看第一个kWhatSetDataSource，创建了一个GenericSource对象，作为消息内容发出：

```C++
void NuPlayer::onMessageReceived(const sp<AMessage> &msg) {
    switch (msg->what()) {
        case kWhatSetDataSource:
        {
            ALOGV("kWhatSetDataSource");

            CHECK(mSource == NULL);

            status_t err = OK;
            sp<RefBase> obj;
            CHECK(msg->findObject("source", &obj));
            if (obj != NULL) {
                Mutex::Autolock autoLock(mSourceLock);
                mSource = static_cast<Source *>(obj.get());
            } else {
                err = UNKNOWN_ERROR;
            }

            CHECK(mDriver != NULL);
            // 升级为强指针，然后通知NuPlayerDriver
            sp<NuPlayerDriver> driver = mDriver.promote();
            if (driver != NULL) {
                driver->notifySetDataSourceCompleted(err);
            }
            break;
        }
        ...
```

接收到kWhatSetDataSource的消息接收到后，直接通知下NuPlayerDriver，这块没有太多耗时的操作，异步与否其实无所谓。

重点看下另一个AMessage：kWhatSourceNotify

```C++
    sp<AMessage> notify = new AMessage(kWhatSourceNotify, this);

    sp<GenericSource> source =
            new GenericSource(notify, mUIDValid, mUID, mMediaClock);

    status_t err = source->setDataSource(fd, offset, length);
```

看下这个类：GenericSource：

> GenericSource

```C++
struct NuPlayer::GenericSource : public NuPlayer::Source,
                                 public MediaBufferObserver {
                                 }
```

GenericSource是NuPlayer::Source的一个子类，主要用于本地多媒体文件的读取解析，其他还有：

> NuPlayer::Source的子类有：GenericSource、HTTPLiveSource、RTSPSource、StreamingSource

先看GenericSource的构造函数：

```C++
NuPlayer::GenericSource::GenericSource(
        const sp<AMessage> &notify,
        bool uidValid,
        uid_t uid,
        const sp<MediaClock> &mediaClock)
    : Source(notify),
    	...  
	{
    ALOGV("GenericSource");
    CHECK(mediaClock != NULL);

    mBufferingSettings.mInitialMarkMs = kInitialMarkMs;
    mBufferingSettings.mResumePlaybackMarkMs = kResumePlaybackMarkMs;
    resetDataSource();
}

explicit Source(const sp<AMessage> &notify)
    : mNotify(notify) {
}

sp<AMessage> mNotify;
```

注意到notify被传过来了。

继续看GenericSource::setDataSource

```C++
status_t NuPlayer::GenericSource::setDataSource(
        int fd, int64_t offset, int64_t length) {
    Mutex::Autolock _l(mLock);
    ALOGV("setDataSource %d/%lld/%lld (%s)", fd, (long long)offset, (long long)length, nameForFd(fd).c_str());

    resetDataSource();

    mFd.reset(dup(fd));
    mOffset = offset;
    mLength = length;

    // delay data source creation to prepareAsync() to avoid blocking
    // the calling thread in setDataSource for any significant time.
    return OK;
}
```

做了写状态设置，跟AudioTrack没有什么关系，就不继续展开看了。

### 3.4 prepare

继续看prepare()函数：

> mediaplayer::prepare()

```C++
status_t MediaPlayer::prepare()
{
    ALOGV("prepare");
    Mutex::Autolock _l(mLock);
    mLockThreadId = getThreadId();
    if (mPrepareSync) {
        mLockThreadId = 0;
        return -EALREADY;
    }
    mPrepareSync = true;
    status_t ret = prepareAsync_l();
    if (ret != NO_ERROR) {
        mLockThreadId = 0;
        return ret;
    }

    if (mPrepareSync) {
        mSignal.wait(mLock);  // wait for prepare done
        mPrepareSync = false;
    }
    ALOGV("prepare complete - status=%d", mPrepareStatus);
    mLockThreadId = 0;
    return mPrepareStatus;
}
```

```c++
status_t MediaPlayer::prepareAsync_l()
{
    if ( (mPlayer != 0) && ( mCurrentState & (MEDIA_PLAYER_INITIALIZED | MEDIA_PLAYER_STOPPED) ) ) {
        if (mAudioAttributesParcel != NULL) {
            mPlayer->setParameter(KEY_PARAMETER_AUDIO_ATTRIBUTES, *mAudioAttributesParcel);
        } else {
            mPlayer->setAudioStreamType(mStreamType);
        }
        mCurrentState = MEDIA_PLAYER_PREPARING;
        return mPlayer->prepareAsync();
    }
    ALOGE("prepareAsync called in state %d, mPlayer(%p)", mCurrentState, mPlayer.get());
    return INVALID_OPERATION;
}
```

分析setDataSource的时候已知，MediaPlayer的mPlayer是MediaPlayerService::Client的代理：

> MediaPlayerService::Client

```C++
status_t MediaPlayerService::Client::prepareAsync()
{
    ALOGV("[%d] prepareAsync", mConnId);
    sp<MediaPlayerBase> p = getPlayer();
    if (p == 0) return UNKNOWN_ERROR;
    status_t ret = p->prepareAsync();
#if CALLBACK_ANTAGONIZER
    ALOGD("start Antagonizer");
    if (ret == NO_ERROR) mAntagonizer->start();
#endif
    return ret;
}
```

> NuPlayerDriver::prepareAsync

```C++
status_t NuPlayerDriver::prepareAsync() {
    ALOGV("prepareAsync(%p)", this);
    Mutex::Autolock autoLock(mLock);

    switch (mState) {
        case STATE_UNPREPARED:
            mState = STATE_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->prepareAsync();
            return OK;
        case STATE_STOPPED:
            // this is really just paused. handle as seek to start
            mAtEOS = false;
            mState = STATE_STOPPED_AND_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->seekToAsync(0, MediaPlayerSeekMode::SEEK_PREVIOUS_SYNC /* mode */,
                    true /* needNotify */);
            return OK;
        default:
            return INVALID_OPERATION;
    };
}
```

#### 3.4.1 mState值是多少？

首先看下NuPlayerDriver::mState，在执行setDataSource后，NuPlayer会通知NuPlayerDriver执行完成：

```C++
void NuPlayer::onMessageReceived(const sp<AMessage> &msg) {
    switch (msg->what()) {
        case kWhatSetDataSource:
        {
            ALOGV("kWhatSetDataSource");

            CHECK(mSource == NULL);

            status_t err = OK;
            sp<RefBase> obj;
            CHECK(msg->findObject("source", &obj));
            if (obj != NULL) {
                Mutex::Autolock autoLock(mSourceLock);
                mSource = static_cast<Source *>(obj.get());
            } else {
                err = UNKNOWN_ERROR;
            }

            CHECK(mDriver != NULL);
            // 升级为强指针，然后通知NuPlayerDriver
            sp<NuPlayerDriver> driver = mDriver.promote();
            if (driver != NULL) {
                driver->notifySetDataSourceCompleted(err);
            }
            break;
        }
        ...
```

```C++
void NuPlayerDriver::notifySetDataSourceCompleted(status_t err) {
    Mutex::Autolock autoLock(mLock);

    CHECK_EQ(mState, STATE_SET_DATASOURCE_PENDING);

    mAsyncResult = err;
    mState = (err == OK) ? STATE_UNPREPARED : STATE_IDLE;
    mCondition.broadcast();
}
```

可以看到，此时mState为STATE_UNPREPARED

#### 3.4.2 NuPlayer::prepareAsync

回到NuPlayerDriver::prepareAsync：

```C++
status_t NuPlayerDriver::prepareAsync() {
    ALOGV("prepareAsync(%p)", this);
    Mutex::Autolock autoLock(mLock);

    switch (mState) {
        case STATE_UNPREPARED:
            mState = STATE_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->prepareAsync();
            return OK;
        case STATE_STOPPED:
            // this is really just paused. handle as seek to start
            mAtEOS = false;
            mState = STATE_STOPPED_AND_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->seekToAsync(0, MediaPlayerSeekMode::SEEK_PREVIOUS_SYNC /* mode */,
                    true /* needNotify */);
            return OK;
        default:
            return INVALID_OPERATION;
    };
}
```

上面已经分析过了，mState为STATE_UNPREPARED，所以执行NuPlayer::prepareAsync()

```C++
void NuPlayer::prepareAsync() {
    ALOGV("prepareAsync");

    (new AMessage(kWhatPrepare, this))->post();
}
```

```C++
        case kWhatPrepare:
        {
            ALOGV("onMessageReceived kWhatPrepare");

            mSource->prepareAsync();
            break;
        }
```

对于本地播放源，mSource是GenericSource，继续跟踪：

```C++
void NuPlayer::GenericSource::prepareAsync() {
    Mutex::Autolock _l(mLock);
    ALOGV("prepareAsync: (looper: %d)", (mLooper != NULL));

    if (mLooper == NULL) {
        mLooper = new ALooper;
        mLooper->setName("generic");
        mLooper->start();

        mLooper->registerHandler(this);
    }

    sp<AMessage> msg = new AMessage(kWhatPrepareAsync, this);
    msg->post();
}
```

```C++
    switch (msg->what()) {
      case kWhatPrepareAsync:
      {
          onPrepareAsync();
          break;
      }
```

```c++
void NuPlayer::GenericSource::onPrepareAsync() {
    mDisconnectLock.lock();
    ALOGV("onPrepareAsync: mDataSource: %d", (mDataSource != NULL));

    // delayed data source creation
    if (mDataSource == NULL) {
        // set to false first, if the extractor
        // comes back as secure, set it to true then.
        mIsSecure = false;

        if (!mUri.empty()) {
            // 从网络创建MediaPlayer时才走此分支，此处省略
        } else {
            if (property_get_bool("media.stagefright.extractremote", true) &&
                    !PlayerServiceFileSource::requiresDrm(
                            mFd.get(), mOffset, mLength, nullptr /* mime */)) {
                sp<IBinder> binder =
                        defaultServiceManager()->getService(String16("media.extractor"));
                if (binder != nullptr) {
                    ALOGD("FileSource remote");
                    sp<IMediaExtractorService> mediaExService(
                            interface_cast<IMediaExtractorService>(binder));
                    sp<IDataSource> source;
                    mediaExService->makeIDataSource(base::unique_fd(dup(mFd.get())), mOffset, mLength, &source);
                    ALOGV("IDataSource(FileSource): %p %d %lld %lld",
                            source.get(), mFd.get(), (long long)mOffset, (long long)mLength);
                    if (source.get() != nullptr) {
                        mDataSource = CreateDataSourceFromIDataSource(source);
                    } else {
                        ALOGW("extractor service cannot make data source");
                    }
                } else {
                    ALOGW("extractor service not running");
                }
            }
            if (mDataSource == nullptr) {
                ALOGD("FileSource local");
                mDataSource = new PlayerServiceFileSource(dup(mFd.get()), mOffset, mLength);
            }
        }

        if (mDataSource == NULL) {
            ALOGE("Failed to create data source!");
            mDisconnectLock.unlock();
            notifyPreparedAndCleanup(UNKNOWN_ERROR);
            return;
        }
    }

    if (mDataSource->flags() & DataSource::kIsCachingDataSource) {
        mCachedSource = static_cast<NuCachedSource2 *>(mDataSource.get());
    }

    mDisconnectLock.unlock();

    // For cached streaming cases, we need to wait for enough
    // buffering before reporting prepared.
    mIsStreaming = (mCachedSource != NULL);

    // init extractor from data source
    status_t err = initFromDataSource();

    if (err != OK) {
        ALOGE("Failed to init from data source!");
        notifyPreparedAndCleanup(err);
        return;
    }

    if (mVideoTrack.mSource != NULL) {
        sp<MetaData> meta = getFormatMeta_l(false /* audio */);
        sp<AMessage> msg = new AMessage;
        err = convertMetaDataToMessage(meta, &msg);
        if(err != OK) {
            notifyPreparedAndCleanup(err);
            return;
        }
        notifyVideoSizeChanged(msg);
    }

    notifyFlagsChanged(
            // FLAG_SECURE will be known if/when prepareDrm is called by the app
            // FLAG_PROTECTED will be known if/when prepareDrm is called by the app
            FLAG_CAN_PAUSE |
            FLAG_CAN_SEEK_BACKWARD |
            FLAG_CAN_SEEK_FORWARD |
            FLAG_CAN_SEEK);

    finishPrepareAsync();

    ALOGV("onPrepareAsync: Done");
}
```

这块代码比较复杂，也不展开了，跟AudioTrack关系不大，后面有时间再研究下。

#### 3.4.3 另一条分支。。。

再回到NuPlayerDriver::prepareAsync

```C++
status_t NuPlayerDriver::prepareAsync() {
    ALOGV("prepareAsync(%p)", this);
    Mutex::Autolock autoLock(mLock);

    switch (mState) {
        case STATE_UNPREPARED:
            mState = STATE_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->prepareAsync();
            return OK;
        case STATE_STOPPED:
            // this is really just paused. handle as seek to start
            mAtEOS = false;
            mState = STATE_STOPPED_AND_PREPARING;
            mIsAsyncPrepare = true;
            mPlayer->seekToAsync(0, MediaPlayerSeekMode::SEEK_PREVIOUS_SYNC /* mode */,
                    true /* needNotify */);
            return OK;
        default:
            return INVALID_OPERATION;
    };
}
```

当mState是STATE_STOPPED时，执行prepare()是会走到创建AudioTrack的流程的，具体流程见：

> https://blog.csdn.net/zhuyong006/article/details/86246540

这篇博客下面红框的部分可能是有误的，没有找到先prepare再stop再prepare的逻辑。

**只能暂时理解为，如果一个MediaPlayer执行过stop，再prepare的时候就会走到这个分支，直接创建AudioTrack。按这个理解，这个分支不是一个常见的场景，所以就不展开了，感兴趣可以参考上面的博客。**

综上，在没走到这个分支的情况下，调用prepare()是不会创建AudioTrack的

![image-20210921172130833](.\images\image-20210921172130833.png)

### 3.5 start

看下start，这次直奔主题，直接到NuPlayer::start

```C++
void NuPlayer::start() {
    (new AMessage(kWhatStart, this))->post();
}
```

```c++
        case kWhatStart:
        {
            ALOGV("kWhatStart");
            if (mStarted) {
                // do not resume yet if the source is still buffering
                if (!mPausedForBuffering) {
                    onResume();
                }
            } else {
                onStart();
            }
            mPausedByClient = false;
            break;
        }
```

来到NuPlayer::onStart()

```C++
void NuPlayer::onStart(int64_t startPositionUs, MediaPlayerSeekMode mode) {
    // 上面的代码都忽略，只看最后一行
    ...

    postScanSources();
}
```

```C++
void NuPlayer::postScanSources() {
    if (mScanSourcesPending) {
        return;
    }

    sp<AMessage> msg = new AMessage(kWhatScanSources, this);
    msg->setInt32("generation", mScanSourcesGeneration);
    msg->post();

    mScanSourcesPending = true;
}
```

```C++
case kWhatScanSources:
        {
            // 仅保留跟AudioTrack创建有关的
            if (mAudioSink != NULL && mAudioDecoder == NULL) {
                if (instantiateDecoder(true, &mAudioDecoder) == -EWOULDBLOCK) {
                    rescan = true;
                }
            }
        }
```

继续，来到instantiateDecoder()

```C++
status_t NuPlayer::instantiateDecoder(
        bool audio, sp<DecoderBase> *decoder, bool checkAudioModeChange) {
    if (audio) {
        sp<AMessage> notify = new AMessage(kWhatAudioNotify, this);
        ++mAudioDecoderGeneration;
        notify->setInt32("generation", mAudioDecoderGeneration);

        if (checkAudioModeChange) {
            determineAudioModeChange(format);
        }
    }
}
```

```C++
void NuPlayer::determineAudioModeChange(const sp<AMessage> &audioFormat) {
    if (canOffload) {
        if (!mOffloadAudio) {
            mRenderer->signalEnableOffloadAudio();
        }
        // open audio sink early under offload mode.
        tryOpenAudioSinkForOffload(audioFormat, audioMeta, hasVideo);
    } else {
        if (mOffloadAudio) {
            mRenderer->signalDisableOffloadAudio();
            mOffloadAudio = false;
        }
    }
}
```

```C++
void NuPlayer::tryOpenAudioSinkForOffload(
        const sp<AMessage> &format, const sp<MetaData> &audioMeta, bool hasVideo) {

    status_t err = mRenderer->openAudioSink(
            format, true /* offloadOnly */, hasVideo,
            AUDIO_OUTPUT_FLAG_NONE, &mOffloadAudio, mSource->isStreaming());
    if (err != OK) {
        // Any failure we turn off mOffloadAudio.
        mOffloadAudio = false;
    } else if (mOffloadAudio) {
        sendMetaDataToHal(mAudioSink, audioMeta);
    }
}
```

mRenderer对应NuPlayerRenderer：

```c++
status_t NuPlayer::Renderer::openAudioSink(
        const sp<AMessage> &format,
        bool offloadOnly,
        bool hasVideo,
        uint32_t flags,
        bool *isOffloaded,
        bool isStreaming) {
    sp<AMessage> msg = new AMessage(kWhatOpenAudioSink, this);
    msg->setMessage("format", format);
    msg->setInt32("offload-only", offloadOnly);
    msg->setInt32("has-video", hasVideo);
    msg->setInt32("flags", flags);
    msg->setInt32("isStreaming", isStreaming);

    sp<AMessage> response;
    status_t postStatus = msg->postAndAwaitResponse(&response);

    int32_t err;
    if (postStatus != OK || response.get() == nullptr || !response->findInt32("err", &err)) {
        err = INVALID_OPERATION;
    } else if (err == OK && isOffloaded != NULL) {
        int32_t offload;
        CHECK(response->findInt32("offload", &offload));
        *isOffloaded = (offload != 0);
    }
    return err;
}
```

kWhatOpenAudioSink处理线程：

```C++
        case kWhatOpenAudioSink:
        {
            sp<AMessage> format;
            CHECK(msg->findMessage("format", &format));

            int32_t offloadOnly;
            CHECK(msg->findInt32("offload-only", &offloadOnly));

            int32_t hasVideo;
            CHECK(msg->findInt32("has-video", &hasVideo));

            uint32_t flags;
            CHECK(msg->findInt32("flags", (int32_t *)&flags));

            uint32_t isStreaming;
            CHECK(msg->findInt32("isStreaming", (int32_t *)&isStreaming));

            status_t err = onOpenAudioSink(format, offloadOnly, hasVideo, flags, isStreaming);

            sp<AMessage> response = new AMessage;
            response->setInt32("err", err);
            response->setInt32("offload", offloadingAudio());

            sp<AReplyToken> replyID;
            CHECK(msg->senderAwaitsResponse(&replyID));
            response->postReply(replyID);

            break;
        }
```

onOpenAudioSink：

```C++
status_t NuPlayer::Renderer::onOpenAudioSink(
        const sp<AMessage> &format,
        bool offloadOnly,
        bool hasVideo,
        uint32_t flags,
        bool isStreaming) {

            err = mAudioSink->open(
                    sampleRate,
                    numChannels,
                    (audio_channel_mask_t)channelMask,
                    audioFormat,
                    0 /* bufferCount - unused */,
                    &NuPlayer::Renderer::AudioSinkCallback,
                    this,
                    (audio_output_flags_t)offloadFlags,
                    &offloadInfo);


}
```

这里的mAudioSink中的setDataSource_pre有完成设置，指向的是MediaPlayerService中的AudioOutput

```C++
status_t MediaPlayerService::AudioOutput::open(
        uint32_t sampleRate, int channelCount, audio_channel_mask_t channelMask,
        audio_format_t format, int bufferCount,
        AudioCallback cb, void *cookie,
        audio_output_flags_t flags,
        const audio_offload_info_t *offloadInfo,
        bool doNotReconnect,
        uint32_t suggestedFrameCount)
{
   
            t = new AudioTrack(
                    mStreamType,
                    sampleRate,
                    format,
                    channelMask,
                    frameCount,
                    flags,
                    NULL, // callback
                    NULL, // user data
                    0, // notification frames
                    mSessionId,
                    AudioTrack::TRANSFER_DEFAULT,
                    NULL, // offload info
                    mUid,
                    mPid,
                    mAttributes,
                    doNotReconnect,
                    targetSpeed,
                    mSelectedDeviceId,
                    mOpPackageName);

			mTrack = t;
}
```

综上，总算是找到了AudioTrack的创建位置，最终赋值给了MediaPlayerService的mTrack成员

## 4. AudioTrack

Android提供给应用层两个类用于播放音频，分别是MediaPlayer.java和AudioTrack.java，通过上节的梳理，MediaPlayer最终也是创建了AudioTrack。本节就来系统地了解下AudioTrack。

### 4.1 AudioTrack.java

AudioTrack.java提供了两种播放方式：静态播放和流播放：

```
// 静态播放
AudioTrack audioTrack = new AudioTrack();
audioTrack.write();
audioTrack.play();

// 流播放
AudioTrack audioTrack = new AudioTrack();
audioTrack.play();
audioTrack.write();	// 子线程
```

#### 4.2 new AudioTrack()

这节主要看下应用层创建AudioTrack()时，是怎么调用到startOutput()的



#### 4.3 AudioTrack.play()

AudioTrack.play()通过JNI最终调用到native层的AudioTrack::start()

> AudioTrack::start()

```C++
status_t AudioTrack::start()
{
    AutoMutex lock(mLock);

    if (mState == STATE_ACTIVE) {
        return INVALID_OPERATION;
    }

    ALOGV("%s(%d): prior state:%s", __func__, mPortId, stateToString(mState));

    // Defer logging here due to OpenSL ES repeated start calls.
    // TODO(b/154868033) after fix, restore this logging back to the beginning of start().
    const int64_t beginNs = systemTime();
    status_t status = NO_ERROR; // logged: make sure to set this before returning.
    mediametrics::Defer defer([&] {
        mediametrics::LogItem(mMetricsId)
            .set(AMEDIAMETRICS_PROP_CALLERNAME,
                    mCallerName.empty()
                    ? AMEDIAMETRICS_PROP_CALLERNAME_VALUE_UNKNOWN
                    : mCallerName.c_str())
            .set(AMEDIAMETRICS_PROP_EVENT, AMEDIAMETRICS_PROP_EVENT_VALUE_START)
            .set(AMEDIAMETRICS_PROP_EXECUTIONTIMENS, (int64_t)(systemTime() - beginNs))
            .set(AMEDIAMETRICS_PROP_STATE, stateToString(mState))
            .set(AMEDIAMETRICS_PROP_STATUS, (int32_t)status)
            .record(); });


    mInUnderrun = true;

    State previousState = mState;
    if (previousState == STATE_PAUSED_STOPPING) {
        mState = STATE_STOPPING;
    } else {
        mState = STATE_ACTIVE;
    }
    (void) updateAndGetPosition_l();

    // save start timestamp
    if (isOffloadedOrDirect_l()) {
        if (getTimestamp_l(mStartTs) != OK) {
            mStartTs.mPosition = 0;
        }
    } else {
        if (getTimestamp_l(&mStartEts) != OK) {
            mStartEts.clear();
        }
    }
    mStartNs = systemTime(); // save this for timestamp adjustment after starting.
    if (previousState == STATE_STOPPED || previousState == STATE_FLUSHED) {
        // reset current position as seen by client to 0
        mPosition = 0;
        mPreviousTimestampValid = false;
        mTimestampStartupGlitchReported = false;
        mTimestampRetrogradePositionReported = false;
        mTimestampRetrogradeTimeReported = false;
        mTimestampStallReported = false;
        mTimestampStaleTimeReported = false;
        mPreviousLocation = ExtendedTimestamp::LOCATION_INVALID;

        if (!isOffloadedOrDirect_l()
                && mStartEts.mTimeNs[ExtendedTimestamp::LOCATION_SERVER] > 0) {
            // Server side has consumed something, but is it finished consuming?
            // It is possible since flush and stop are asynchronous that the server
            // is still active at this point.
            ALOGV("%s(%d): server read:%lld  cumulative flushed:%lld  client written:%lld",
                    __func__, mPortId,
                    (long long)(mFramesWrittenServerOffset
                            + mStartEts.mPosition[ExtendedTimestamp::LOCATION_SERVER]),
                    (long long)mStartEts.mFlushed,
                    (long long)mFramesWritten);
            // mStartEts is already adjusted by mFramesWrittenServerOffset, so we delta adjust.
            mFramesWrittenServerOffset -= mStartEts.mPosition[ExtendedTimestamp::LOCATION_SERVER];
        }
        mFramesWritten = 0;
        mProxy->clearTimestamp(); // need new server push for valid timestamp
        mMarkerReached = false;

        // For offloaded tracks, we don't know if the hardware counters are really zero here,
        // since the flush is asynchronous and stop may not fully drain.
        // We save the time when the track is started to later verify whether
        // the counters are realistic (i.e. start from zero after this time).
        mStartFromZeroUs = mStartNs / 1000;

        // force refresh of remaining frames by processAudioBuffer() as last
        // write before stop could be partial.
        mRefreshRemaining = true;

        // for static track, clear the old flags when starting from stopped state
        if (mSharedBuffer != 0) {
            android_atomic_and(
            ~(CBLK_LOOP_CYCLE | CBLK_LOOP_FINAL | CBLK_BUFFER_END),
            &mCblk->mFlags);
        }
    }
    mNewPosition = mPosition + mUpdatePeriod;
    int32_t flags = android_atomic_and(~(CBLK_STREAM_END_DONE | CBLK_DISABLED), &mCblk->mFlags);

    if (!(flags & CBLK_INVALID)) {
        status = mAudioTrack->start();
        if (status == DEAD_OBJECT) {
            flags |= CBLK_INVALID;
        }
    }
    if (flags & CBLK_INVALID) {
        status = restoreTrack_l("start");
    }

    // resume or pause the callback thread as needed.
    sp<AudioTrackThread> t = mAudioTrackThread;
    if (status == NO_ERROR) {
        if (t != 0) {
            if (previousState == STATE_STOPPING) {
                mProxy->interrupt();
            } else {
                t->resume();
            }
        } else {
            mPreviousPriority = getpriority(PRIO_PROCESS, 0);
            get_sched_policy(0, &mPreviousSchedulingGroup);
            androidSetThreadPriority(0, ANDROID_PRIORITY_AUDIO);
        }

        // Start our local VolumeHandler for restoration purposes.
        mVolumeHandler->setStarted();
    } else {
        ALOGE("%s(%d): status %d", __func__, mPortId, status);
        mState = previousState;
        if (t != 0) {
            if (previousState != STATE_STOPPING) {
                t->pause();
            }
        } else {
            setpriority(PRIO_PROCESS, 0, mPreviousPriority);
            set_sched_policy(0, mPreviousSchedulingGroup);
        }
    }

    return status;
}
```

